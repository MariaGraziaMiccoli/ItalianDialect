{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dU75bX143acD"
      },
      "source": [
        "#**Italian Dialects: NLP For Local Linguistics**\n",
        "\n",
        "The idea behind this project is the task proposed by GeoLingIt Shared Task and published on Avalita, in which, given a dataset containing tweets written in Italian dialect associated with the region of origin of the dialect, you had to predict the region of origin of a dialect text never seen. This project extends the task with an extra phase: the translation of the dialect text in italian."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBszQahJplR6",
        "outputId": "b5301eea-18e3-422c-d9dd-e5527a3d58c0",
        "ExecuteTime": {
          "end_time": "2024-06-21T10:54:29.697857Z",
          "start_time": "2024-06-21T10:53:29.505206Z"
        },
        "collapsed": true
      },
      "source": [
        "#installation of the necessary libraries\n",
        "!pip install cleantext\n",
        "!pip install spacy\n",
        "!pip install keras\n",
        "!pip install nltk\n",
        "!pip install -U spaCy\n",
        "!python -m spacy download it_core_news_sm\n",
        "!pip install tensorflow"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cleantext\n",
            "  Downloading cleantext-1.1.4-py3-none-any.whl (4.9 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from cleantext) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->cleantext) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->cleantext) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->cleantext) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->cleantext) (4.66.4)\n",
            "Installing collected packages: cleantext\n",
            "Successfully installed cleantext-1.1.4\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: spaCy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spaCy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spaCy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spaCy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spaCy) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spaCy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spaCy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spaCy) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spaCy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spaCy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spaCy) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spaCy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spaCy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spaCy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spaCy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spaCy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spaCy) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spaCy) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spaCy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spaCy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spaCy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spaCy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spaCy) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spaCy) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spaCy) (0.1.2)\n",
            "Collecting it-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/it_core_news_sm-3.7.0/it_core_news_sm-3.7.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from it-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->it-core-news-sm==3.7.0) (0.1.2)\n",
            "Installing collected packages: it-core-news-sm\n",
            "Successfully installed it-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('it_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Analysis of the dataset*\n",
        "\n",
        "The starting dataset consists of two parts: dev and train. Analyzing the number of sentences associated with each Italian region, we noticed a remarkable imbalance and a small number of examples. As a result the two files were merged and a over-sampling phase was planned (detailed view later).\n",
        "Analyzing the sentences, we saw that they needed a preprocessing phase to normalize everything and leave only the text we needed."
      ],
      "metadata": {
        "id": "EgFkoFp1uyez"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8Ges3kRY-r1",
        "ExecuteTime": {
          "end_time": "2024-06-21T11:36:17.265414Z",
          "start_time": "2024-06-21T11:36:12.804687Z"
        }
      },
      "source": [
        "#Import of the necessary libraries\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from cleantext import clean\n",
        "import numpy as np\n",
        "from random import randint"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4Bsgfdzqjsj",
        "ExecuteTime": {
          "end_time": "2024-06-21T11:36:29.125778Z",
          "start_time": "2024-06-21T11:36:17.267277Z"
        },
        "collapsed": true
      },
      "source": [
        "#Loading of the train dataset\n",
        "df = None\n",
        "with open('TRAIN_NLP_DIALECT.csv', 'r', encoding='latin-1') as f:\n",
        "    for i,line in enumerate(f.readlines()):\n",
        "        if i == 0:\n",
        "          columns = line.strip().split(';')\n",
        "          columns = columns[1:]\n",
        "          df = pd.DataFrame(columns=columns)\n",
        "        else:\n",
        "          line = line.lower()\n",
        "          row = line.strip().split(';')[1:]\n",
        "          if len(row) > len(columns):\n",
        "            target = row.pop(-1)\n",
        "            val = ''\n",
        "            for i, el in enumerate(row):\n",
        "              val += el\n",
        "              if i < len(row)-1:\n",
        "                val += ';'\n",
        "            row = [val]\n",
        "            row.append(target)\n",
        "          df.loc[i] = row"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading of the dev dataset\n",
        "dev = None\n",
        "with open('FinalTest.csv', 'r', encoding='latin-1') as f:\n",
        "    for i,line in enumerate(f.readlines()):\n",
        "        if i == 0:\n",
        "          columns = line.strip().split(',')\n",
        "          columns = columns[2:]\n",
        "          dev = pd.DataFrame(columns=columns)\n",
        "        else:\n",
        "          line = line.lower()\n",
        "          row = line.strip().split(',')[2:]\n",
        "          if len(row) > len(columns):\n",
        "            target = row.pop(-1)\n",
        "            val = ''\n",
        "            for i, el in enumerate(row):\n",
        "              val += el\n",
        "              if i < len(row)-1:\n",
        "                val += ','\n",
        "            row = [val]\n",
        "            row.append(target)\n",
        "            dev.loc[len(dev)] = row"
      ],
      "metadata": {
        "id": "jcu_mEaFhjNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4R_1Dz4q_EF",
        "outputId": "615ef527-1143-41fb-c7d0-3961078f349b",
        "ExecuteTime": {
          "end_time": "2024-06-21T11:36:29.514178Z",
          "start_time": "2024-06-21T11:36:29.126777Z"
        }
      },
      "source": [
        "print(dev)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  text     region\n",
            "0     mortacci, na roba che nse po' vede, por, na c...      lazio\n",
            "1     ou belin, ma mi avevano detto che non finiva ...    liguria\n",
            "2     ora che sta a casa da due anni, a capit ca ni...   campania\n",
            "3     e er boja stava all'ordine der giorno. adesso...      lazio\n",
            "4     quando e uscito 50 sfumature di grigio, tutte...   calabria\n",
            "..                                                 ...        ...\n",
            "183   distratto. no. ieri no gho vu tempo e anco so...     veneto\n",
            "184   belin coerenza, sono riusciti in 2anni ad ann...    liguria\n",
            "185   incredibilmente, alla lunga, ne sono usciti b...  lombardia\n",
            "186   che domenica e senza : so maista' u cannolu s...    sicilia\n",
            "187   quando decideva di giocarla sul serio, ce n'e...     puglia\n",
            "\n",
            "[188 rows x 2 columns]\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJnf5h_tf8YM",
        "outputId": "4a397f3d-efbf-44be-c55c-6f0e3564e4c6",
        "ExecuteTime": {
          "end_time": "2024-06-21T11:36:30.194857Z",
          "start_time": "2024-06-21T11:36:29.727215Z"
        }
      },
      "source": [
        "df['region'].value_counts()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "region\n",
              "lazio                    5587\n",
              "campania                 3016\n",
              "veneto                    764\n",
              "lombardia                 688\n",
              "sicilia                   612\n",
              "toscana                   418\n",
              "sardegna                  359\n",
              "emilia romagna            319\n",
              "calabria                  281\n",
              "puglia                    264\n",
              "piemonte                  236\n",
              "liguria                   223\n",
              "friuli-venezia giulia     218\n",
              "marche                    179\n",
              "abruzzo                   150\n",
              "umbria                    136\n",
              "trentino-alto adige        52\n",
              "basilicata                 49\n",
              "molise                     35\n",
              "valle d'aosta              14\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36nYYE5JiFvC",
        "outputId": "741e3aa0-9631-4ee9-c475-06d13cb22e04",
        "ExecuteTime": {
          "end_time": "2024-06-21T11:36:30.630960Z",
          "start_time": "2024-06-21T11:36:30.196854Z"
        }
      },
      "source": [
        "dev['region'].value_counts()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "region\n",
              "campania                 30\n",
              "lazio                    27\n",
              "lombardia                21\n",
              "emilia romagna           17\n",
              "toscana                  16\n",
              "veneto                   15\n",
              "sicilia                  11\n",
              "liguria                   9\n",
              "friuli-venezia giulia     9\n",
              "puglia                    9\n",
              "calabria                  8\n",
              "sardegna                  8\n",
              "piemonte                  8\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wav-U6Wzt9el",
        "ExecuteTime": {
          "end_time": "2024-06-21T11:36:31.043818Z",
          "start_time": "2024-06-21T11:36:30.632958Z"
        }
      },
      "source": [
        "df['region'] = df['region'].str.lower()\n",
        "dev['region'] = dev['region'].str.lower()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see the unbalance of the dataset and the presence of Minonitary classes."
      ],
      "metadata": {
        "id": "nQLMyMx2RmvU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rt9YxyQiRMX"
      },
      "source": [
        "## **Pre processing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmW6KRWciyzN"
      },
      "source": [
        "The initial datasets were in tsv format to allow different users to work with different libraries on them. Since pandas was used in this project, the dataset was converted to csv format and this led to the automatic addition of the column 'Unnamed: 0' that, in this preprocessing sentence, we will remove."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ng8ihkUpid_T"
      },
      "outputs": [],
      "source": [
        "ds = df.drop(['Unnamed: 0'],axis = 1)\n",
        "dev = dev.drop(['Unnamed: 0'], axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRWRVWcni4ev"
      },
      "source": [
        "Now the actual preprocessing phase begins. Then let’s remove from the phrases: Twitter tags (current X), emoticons and hashtags."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2L7ENBG4f3GX"
      },
      "outputs": [],
      "source": [
        "#Definition of the text cleaning function\n",
        "def clean_the_text(text: str):\n",
        "  pattern = r'\\[.*?\\]|\\#\\w+'\n",
        "  cleaned_text = re.sub(pattern, '', text)\n",
        "  cleaned_text = clean(cleaned_text, no_emoji=True)\n",
        "  return cleaned_text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We apply the function to the two datasets:"
      ],
      "metadata": {
        "id": "h_SC2v4fSsNs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7SA49-TjXtO"
      },
      "outputs": [],
      "source": [
        "#Pre-processing of the train dataset\n",
        "ids = ds['id'].to_numpy()\n",
        "new_text = []\n",
        "\n",
        "for id in tqdm(ids):\n",
        "  clean_text = clean_the_text(ds[ds['id']==id]['text'].values[0])\n",
        "  new_text.append(clean_text)\n",
        "\n",
        "ds['text'] = new_text\n",
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zr5_quRhz-WE"
      },
      "outputs": [],
      "source": [
        "#Pre-processing of the dev dataset\n",
        "ids = dev['id'].to_numpy()\n",
        "new_text = []\n",
        "\n",
        "for id in tqdm(ids):\n",
        "  clean_text = clean_the_text(dev[dev['id']==id]['text'].values[0])\n",
        "  new_text.append(clean_text)\n",
        "\n",
        "dev['text'] = new_text\n",
        "dev"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we proceed with the union of the two datasets, also to have a greater number of total examples.\n",
        "\n"
      ],
      "metadata": {
        "id": "shdQ1IjyTivV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds = pd.concat([df,dev], ignore_index=True)"
      ],
      "metadata": {
        "id": "oSQxjz6fl9wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds['region'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvGC8f7DmRwb",
        "outputId": "1cde5fab-3048-4444-ed97-610f0913330e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "region\n",
              "lazio                    5614\n",
              "campania                 3046\n",
              "veneto                    779\n",
              "lombardia                 709\n",
              "sicilia                   623\n",
              "toscana                   434\n",
              "sardegna                  367\n",
              "emilia romagna            336\n",
              "calabria                  289\n",
              "puglia                    273\n",
              "piemonte                  244\n",
              "liguria                   232\n",
              "friuli-venezia giulia     227\n",
              "marche                    179\n",
              "abruzzo                   150\n",
              "umbria                    136\n",
              "trentino-alto adige        52\n",
              "basilicata                 49\n",
              "molise                     35\n",
              "valle d'aosta              14\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds.to_csv('NLP_Dataset.csv')"
      ],
      "metadata": {
        "id": "8hdmgSuenEdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "br1VuCP0UMea",
        "outputId": "351ed124-9b23-4577-e4e8-1ab9d30d277a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text     region\n",
              "0      Sò dispiacente ca nun m'ha datu tempu de prepa...     marche\n",
              "1                   Tornarò a Ascoli a festa de Pasca,.      marche\n",
              "2               A me m'ha detto ca t'aspettava a jesi,.      marche\n",
              "3                          La gùrdia a stava a guardà,.      marche\n",
              "4                        Porca muntagna si iva a cadè,.      marche\n",
              "...                                                  ...        ...\n",
              "14720   distratto. no. ieri no gho vu tempo e anco so...     veneto\n",
              "14721   belin coerenza, sono riusciti in 2anni ad ann...    liguria\n",
              "14722   incredibilmente, alla lunga, ne sono usciti b...  lombardia\n",
              "14723   che domenica e senza : so maista' u cannolu s...    sicilia\n",
              "14724   quando decideva di giocarla sul serio, ce n'e...     puglia\n",
              "\n",
              "[14725 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-25c7785a-a201-4409-9ad0-96beaff0fb2f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>region</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sò dispiacente ca nun m'ha datu tempu de prepa...</td>\n",
              "      <td>marche</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tornarò a Ascoli a festa de Pasca,.</td>\n",
              "      <td>marche</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A me m'ha detto ca t'aspettava a jesi,.</td>\n",
              "      <td>marche</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>La gùrdia a stava a guardà,.</td>\n",
              "      <td>marche</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Porca muntagna si iva a cadè,.</td>\n",
              "      <td>marche</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14720</th>\n",
              "      <td>distratto. no. ieri no gho vu tempo e anco so...</td>\n",
              "      <td>veneto</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14721</th>\n",
              "      <td>belin coerenza, sono riusciti in 2anni ad ann...</td>\n",
              "      <td>liguria</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14722</th>\n",
              "      <td>incredibilmente, alla lunga, ne sono usciti b...</td>\n",
              "      <td>lombardia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14723</th>\n",
              "      <td>che domenica e senza : so maista' u cannolu s...</td>\n",
              "      <td>sicilia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14724</th>\n",
              "      <td>quando decideva di giocarla sul serio, ce n'e...</td>\n",
              "      <td>puglia</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14725 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25c7785a-a201-4409-9ad0-96beaff0fb2f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-25c7785a-a201-4409-9ad0-96beaff0fb2f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-25c7785a-a201-4409-9ad0-96beaff0fb2f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d1b6b4c0-f75b-4a6b-aa4d-293f6c6c3f5a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d1b6b4c0-f75b-4a6b-aa4d-293f6c6c3f5a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d1b6b4c0-f75b-4a6b-aa4d-293f6c6c3f5a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e3bf128d-df7f-4ad5-bd66-efc2998e8331\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e3bf128d-df7f-4ad5-bd66-efc2998e8331 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 14725,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14637,\n        \"samples\": [\n          \"no intendevo che se la juve vende ronaldo nn credi posso prende uno mejo di dzeko? nel caso della roma sarebbe mejo se lo prendono che rimane ronaldo...penso eh poi magari allegri e malato x dzeko e lo vuole in qualsiasi caso...\",\n          \"cca nisciun e fess. brava clara.\",\n          \"se dice eibraham e non abbram. ma sticazzi, io so piu romana che britannica, quindi lo chiamero abbramme, sentendo la longa mano de mi nonna peggy da lassu che me da na crina dietro la nuca ogni volta.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"region\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"marche\",\n          \"piemonte\",\n          \"friuli-venezia giulia\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset we will work on will be as follows:"
      ],
      "metadata": {
        "id": "zXLM20lrwlhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"NLP_Dataset.csv\")"
      ],
      "metadata": {
        "id": "9ZZR_0SXo4HC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It has 14725 examples, but the Minonitary classes always remain."
      ],
      "metadata": {
        "id": "iiJYpmPJSHbF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuwCcbnQBs8U"
      },
      "source": [
        "# Over-sampling: selection of the suitable model\n",
        "To make over sampling we need a model that allow us to generate sentences in italian dialect. So, in this section, different models were tried.\n",
        "\n",
        "The quality of generative models has been evaluated based on how they generated sentences in Apulian dialect, which presents a regular number of examples on which the model can be based to generate others.\n",
        "Moreover, the Apulian dialect was chosen because we can have a direct evaluation of what was generated.\n",
        "If a model generates a good result for the Apulian dialect, then it will also be used for the dialects of other regions.\n",
        "\n",
        "## 1. N-GRAM Model\n",
        "The first model tested is the N-GRAM model. A language model is a probabilistic model that is used to assign a probability to a sequence of words. For example, if we have a group of words and we take the first word, the model can predict the next word, which is the one with the greatest probability of standing next to the first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kn50gH9vB_Cd",
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2024-06-21T11:37:24.793727Z",
          "start_time": "2024-06-21T11:37:24.786679Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "234c4256-7d72-4722-a4da-46d704828b76"
      },
      "source": [
        "#Import of the necessary libraries\n",
        "import nltk\n",
        "nltk.download(\"all\")\n",
        "\n",
        "from nltk import word_tokenize\n",
        "from nltk.lm import MLE\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_rus.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package tagsets_json to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets_json.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0A-W4TnFGkZL",
        "ExecuteTime": {
          "end_time": "2024-06-21T11:37:25.392878Z",
          "start_time": "2024-06-21T11:37:25.386906Z"
        }
      },
      "source": [
        "#selection of examples from the region of Puglia\n",
        "puglia = df[df['region']=='puglia']['text']"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before applying the model, we must apply the tokenization technique on the dataset examples, that is, divide the phrases into tokens, into pieces.\n",
        "To do this, we use the nltk tokenizer that will output the tokenized text"
      ],
      "metadata": {
        "id": "WrFISmSoYze6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igFOU1R2K-q0",
        "ExecuteTime": {
          "end_time": "2024-06-21T11:37:26.124688Z",
          "start_time": "2024-06-21T11:37:26.000081Z"
        }
      },
      "source": [
        "sents = []\n",
        "for i in puglia:\n",
        "  s = nltk.sent_tokenize(i)\n",
        "  sents.append(s)\n",
        "\n",
        "tokenized_text = [list(map(str.lower, word_tokenize(str(sent))))\n",
        "                  for sent in sents]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can apply the model which, in our case will be a 3-gram model, that is, to calculate the probability of the next word, will consider the above three."
      ],
      "metadata": {
        "id": "_DB0I3ERY1wN"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3j7X6nBB92-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b7a55cf-e068-4ebe-bb0b-95d5f18efeee",
        "ExecuteTime": {
          "end_time": "2024-06-21T11:37:27.234856Z",
          "start_time": "2024-06-21T11:37:27.022552Z"
        }
      },
      "source": [
        "n = 3\n",
        "training_ngrams, padded_sents = padded_everygram_pipeline(n, tokenized_text)\n",
        "#using a model based on Maximum Likelihood Estimation\n",
        "model = MLE(n)\n",
        "model.fit(training_ngrams, padded_sents)\n",
        "\n",
        "#object we need to take the Tokenized phrase and convert it into a single sentence.\n",
        "detokenize = TreebankWordDetokenizer().detokenize\n",
        "\n",
        "#function for generation of sentences\n",
        "def generate_sent(model, num_words, random_seed):\n",
        "    content = []\n",
        "    for token in model.generate(num_words, random_seed=random_seed):\n",
        "        if token == '<s>':\n",
        "            continue\n",
        "        if token == '</s>':\n",
        "            break\n",
        "        content.append(token)\n",
        "    return detokenize(content)\n",
        "\n",
        "print (generate_sent(model, 15, random_seed=6))\n",
        "print (generate_sent(model, 15, random_seed=2))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nan u send canta no pa tutt'appost solo che stavo in fase depressione da campovolo\n",
            "tieni a mente, lu mare c' e mho a ci non fatica doi\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 3-gram model seems to generate valid examples, but, after careful analysis, it has been seen that in reality, the tokenization phase has not been done well. The tokenizer used a basic English dictionary, therefore it does not see every token as a word, but the tokens turn out to be whole sentences. As a result, the same model was tested with a Spacy tokenizer based on an Italian dictionary."
      ],
      "metadata": {
        "id": "BfV4OdjJ4RWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import of the necessary libraries\n",
        "from spacy.lang.it import Italian\n",
        "import spacy\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "\n",
        "import string\n",
        "\n",
        "nlp_it = spacy.load(\"it_core_news_sm\")\n",
        "punctuations = string.punctuation\n",
        "stop_words_it = spacy.lang.it.stop_words.STOP_WORDS\n",
        "parser_it = Italian()"
      ],
      "metadata": {
        "id": "tFDc389X-gNe",
        "ExecuteTime": {
          "end_time": "2024-06-21T11:37:31.504984Z",
          "start_time": "2024-06-21T11:37:30.776378Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizer function\n",
        "def spacy_tokenizer_it(sentence):\n",
        "    mytokens = parser_it(sentence)\n",
        "    mytokens = [ word.text for word in mytokens ]\n",
        "    #removing stop words\n",
        "    mytokens = [ word for word in mytokens if word not in stop_words_it and word not in punctuations]\n",
        "    return mytokens"
      ],
      "metadata": {
        "id": "yYVWrnmvX47I",
        "ExecuteTime": {
          "end_time": "2024-06-21T11:37:33.096391Z",
          "start_time": "2024-06-21T11:37:33.091677Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "puglia = df[df['region']=='puglia']['text']"
      ],
      "metadata": {
        "id": "TxrwGqd0qj8M",
        "ExecuteTime": {
          "end_time": "2024-06-21T11:37:34.903603Z",
          "start_time": "2024-06-21T11:37:34.896307Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sents = []\n",
        "for i in puglia:\n",
        "  s = spacy_tokenizer_it(i)\n",
        "  sents.append(s)\n",
        "\n",
        "tokenized_text = [list(map(str.lower, word_tokenize(str(sent))))\n",
        "                  for sent in sents]"
      ],
      "metadata": {
        "id": "NbtuVa4u--R3",
        "ExecuteTime": {
          "end_time": "2024-06-21T11:37:43.920730Z",
          "start_time": "2024-06-21T11:37:43.743039Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "n = 3\n",
        "training_ngrams, padded_sents = padded_everygram_pipeline(n, tokenized_text)\n",
        "model = MLE(n)\n",
        "model.fit(training_ngrams, padded_sents)\n",
        "\n",
        "detokenize = TreebankWordDetokenizer().detokenize\n",
        "\n",
        "def generate_sent(model, num_words, random_seed):\n",
        "    content = []\n",
        "    for token in model.generate(num_words, random_seed=random_seed):\n",
        "        if token == '<s>':\n",
        "            continue\n",
        "        if token == '</s>':\n",
        "            break\n",
        "        content.append(token)\n",
        "    return detokenize(content)\n",
        "\n",
        "print (generate_sent(model, 50, random_seed=50))\n",
        "print (generate_sent(model, 15, random_seed=2))"
      ],
      "metadata": {
        "id": "zkmgH1iwYO5T",
        "ExecuteTime": {
          "end_time": "2024-06-21T11:37:45.854315Z",
          "start_time": "2024-06-21T11:37:45.522445Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "From here we can see that the tokenizer works very well, but the model is not for us because it simply creates a sequence of words and not meaningful sentences."
      ],
      "metadata": {
        "id": "k8iSSxjx4bfJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Neural networks with Keras\n",
        "\n",
        "Let’s try more complex models based on neural networks made with keras.\n",
        "\n",
        "### LSTM\n",
        "A **Long Short-Term Memory (LSTM)** is a type of recurring neural network (RNN) designed to model long-term data sequences. It is particularly useful for natural language processing (NLP) applications such as text generation. LSTM overcomes the fading gradient problem of traditional RNN due to its special architecture that includes memory cells and port mechanisms (input, output and forget) that control the flow of information.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ccr2z0QZJgo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "puglia = df[df['region']=='puglia']['text']"
      ],
      "metadata": {
        "id": "Yi-7abYmriUM",
        "ExecuteTime": {
          "end_time": "2024-06-21T11:37:48.747948Z",
          "start_time": "2024-06-21T11:37:48.738827Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#library import\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.src.models import Sequential\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import keras.src.utils as ku\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "hZCVqUS-RN9G",
        "ExecuteTime": {
          "end_time": "2024-06-21T11:50:40.365450Z",
          "start_time": "2024-06-21T11:50:40.359608Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-21T11:37:59.936446Z",
          "start_time": "2024-06-21T11:37:59.237563Z"
        },
        "id": "ijq1F0SkyZRl"
      },
      "cell_type": "code",
      "source": [
        "from spacy.lang.it import Italian\n",
        "import string\n",
        "\n",
        "nlp_it = spacy.load(\"it_core_news_sm\")\n",
        "punctuations = string.punctuation\n",
        "stop_words_it = spacy.lang.it.stop_words.STOP_WORDS\n",
        "parser_it = Italian()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizer function\n",
        "def spacy_tokenizer_it(sentence):\n",
        "    mytokens = parser_it(sentence)\n",
        "    mytokens = [ word.text for word in mytokens ]\n",
        "    # remove stop words\n",
        "    mytokens = [ word for word in mytokens if word not in stop_words_it and word not in punctuations ]\n",
        "    # return preprocessed list of tokens\n",
        "    return mytokens"
      ],
      "metadata": {
        "id": "3fS1ClNv9g43",
        "ExecuteTime": {
          "end_time": "2024-06-21T11:37:59.943506Z",
          "start_time": "2024-06-21T11:37:59.937451Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural network-based models need to represent data as token sequences. Accordingly, we define a function to define them."
      ],
      "metadata": {
        "id": "JNaVZ7Y7hsxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sequence_of_tokens(corpus):\n",
        "    word_index = {}\n",
        "    index = 1\n",
        "    input_sequences = []\n",
        "\n",
        "    for line in corpus:\n",
        "        token_list = spacy_tokenizer_it(line)\n",
        "        token_indices = []\n",
        "        for token in token_list:\n",
        "            if token not in word_index:\n",
        "                word_index[token] = index\n",
        "                index += 1\n",
        "            token_indices.append(word_index[token])\n",
        "\n",
        "        for i in range(1, len(token_indices)):\n",
        "            n_gram_sequence = token_indices[:i+1]\n",
        "            input_sequences.append(n_gram_sequence)\n",
        "\n",
        "    total_words = len(word_index) + 1\n",
        "    return input_sequences, total_words\n",
        "\n",
        "inp_sequences, total_words = get_sequence_of_tokens(puglia)\n",
        "print(\"Sequence: \",inp_sequences[:10])\n",
        "print(\"Total words: \",total_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dq0KaEnWRZHx",
        "outputId": "a4358c80-63fa-4729-ffef-a97f5b458949",
        "ExecuteTime": {
          "end_time": "2024-06-21T11:38:00.065246Z",
          "start_time": "2024-06-21T11:37:59.946592Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequence:  [[1, 2], [1, 2, 3], [1, 2, 3, 4], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5, 6], [1, 2, 3, 4, 5, 6, 7], [1, 2, 3, 4, 5, 6, 7, 8], [1, 2, 3, 4, 5, 6, 7, 8, 9], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]]\n",
            "Total words:  1792\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, token sequences can be of variable length, so we define a function to add padding to each sequence to make them the same length."
      ],
      "metadata": {
        "id": "XkdJX1Pnh7zr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_padded_sequences(input_sequences):\n",
        "    max_sequence_len = max([len(x) for x in input_sequences])\n",
        "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "    label = ku.to_categorical(label, num_classes=total_words)\n",
        "    return predictors, label, max_sequence_len\n",
        "\n",
        "predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)\n",
        "print(\"Predictors shape:\", predictors.shape)\n",
        "print(\"Label shape:\", label.shape)\n",
        "print(\"Max sequence length:\", max_sequence_len)"
      ],
      "metadata": {
        "id": "7W2VH_mURta4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0351e301-9f1c-48a3-ad5d-7a19a7289368",
        "ExecuteTime": {
          "end_time": "2024-06-21T11:38:18.498608Z",
          "start_time": "2024-06-21T11:38:18.469275Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictors shape: (2635, 35)\n",
            "Label shape: (2635, 1792)\n",
            "Max sequence length: 36\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(max_sequence_len, total_words):\n",
        "    input_len = max_sequence_len - 1\n",
        "    model = Sequential()\n",
        "\n",
        "    #add Input Embedding Layer, for internal representation of sequences\n",
        "    model.add(Embedding(total_words, 20, input_length=input_len))\n",
        "\n",
        "    #add Hidden LSTM Layer\n",
        "    model.add(LSTM(200))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # Add Output Layer\n",
        "    model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "    return model\n",
        "\n",
        "model = create_model(max_sequence_len, total_words)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXzB18LGRwmE",
        "outputId": "a96fd2fb-bc33-496b-cf77-f179e118785b",
        "ExecuteTime": {
          "end_time": "2024-06-21T11:38:20.429683Z",
          "start_time": "2024-06-21T11:38:20.285241Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 35, 20)            35840     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 200)               176800    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 200)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1792)              360192    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 572832 (2.19 MB)\n",
            "Trainable params: 572832 (2.19 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(predictors, label, epochs = 3, verbose=1)"
      ],
      "metadata": {
        "id": "0zy9kEQQR6tl",
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2024-06-21T11:45:03.654790Z",
          "start_time": "2024-06-21T11:38:36.161194Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted = model.predict(token_list, verbose=0)\n",
        "        predicted = np.argmax(predicted, axis=-1)\n",
        "\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text.title()"
      ],
      "metadata": {
        "id": "89r5TiwJSZxA",
        "ExecuteTime": {
          "end_time": "2024-06-21T11:53:44.164596Z",
          "start_time": "2024-06-21T11:53:44.158271Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"Lu\"\n",
        "next_words = 5\n",
        "generated_text = generate_text(seed_text, next_words, model, max_sequence_len)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "ZApx-GO-SjPJ",
        "ExecuteTime": {
          "end_time": "2024-06-21T11:54:00.524413Z",
          "start_time": "2024-06-21T11:53:59.199770Z"
        },
        "outputId": "0e1bee1d-341d-4f6d-f813-980066690a79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lu     \n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model does not work for our goal."
      ],
      "metadata": {
        "id": "Ju_-wZQc6VNH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VAE\n",
        "Now create a VAE network for text generation from scratch.\n",
        "A **Variational Autoencoder (VAE)** is a type of neural network used to learn latent representations of data, useful for NLP text generation and modeling. The VAE combines autoencoder techniques with probabilistic generative models, allowing new data samples similar to training ones to be generated. Their structure consists of an encoder that maps the input data into a probabilistic latent space and a decoder that reconstructs the original data from the points in the latent space.\n",
        "\n",
        "The first steps are tokenization, creating token sequences, and adding padding to make them the same length.\n",
        "\n"
      ],
      "metadata": {
        "id": "v3CGaJqnJBuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.it import Italian\n",
        "import spacy\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "\n",
        "import string\n",
        "\n",
        "nlp_it = spacy.load(\"it_core_news_sm\")\n",
        "punctuations = string.punctuation\n",
        "stop_words_it = spacy.lang.it.stop_words.STOP_WORDS\n",
        "parser_it = Italian()"
      ],
      "metadata": {
        "id": "T7H5mL9EHfov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizer function\n",
        "def spacy_tokenizer_it(sentence):\n",
        "    mytokens = parser_it(sentence)\n",
        "    mytokens = [ word.text for word in mytokens ]\n",
        "    # remove stop words\n",
        "    mytokens = [ word for word in mytokens if word not in stop_words_it and word not in punctuations ]\n",
        "    # return preprocessed list of tokens\n",
        "    return mytokens"
      ],
      "metadata": {
        "id": "1Q7Qu-ASJpXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "puglia = df[df['region']=='puglia']['text']"
      ],
      "metadata": {
        "id": "Z9NBi1waVp8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "puglia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iFGtPWOVrSI",
        "outputId": "1111f05d-c2e3-401e-fe36-7ac92734cb4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34        una grandissima artista barese ci lascia. add...\n",
              "52        raffaele, mi sembra che sto'parlando con mio ...\n",
              "59                                   bbeddhi comu lu sule \n",
              "122         versione barese. la nonn gastema ! scritto da \n",
              "325       la reazione di mio padre, da incorniciare, co...\n",
              "                               ...                        \n",
              "34208    A maje a diri ca a so' a bona persona, ma a ma...\n",
              "34209    Mare e sole d'estate s'arriprende, a se'mpiede...\n",
              "34210    A maje a diri ca a so' a persona onesta, ma a ...\n",
              "34211    A se' a dispiaccie pe' chidd'ha pecato, a se' ...\n",
              "34212    Cosa faje a sera quand'è freddo e nu viento 'n...\n",
              "Name: text, Length: 1429, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sequence_of_tokens(corpus):\n",
        "    word_index = {}\n",
        "    index = 1\n",
        "    input_sequences = []\n",
        "\n",
        "    for line in corpus:\n",
        "        token_list = spacy_tokenizer_it(line)\n",
        "        token_indices = []\n",
        "        for token in token_list:\n",
        "            if token not in word_index:\n",
        "                word_index[token] = index\n",
        "                index += 1\n",
        "            token_indices.append(word_index[token])\n",
        "\n",
        "        for i in range(1, len(token_indices)):\n",
        "            n_gram_sequence = token_indices[:i+1]\n",
        "            input_sequences.append(n_gram_sequence)\n",
        "\n",
        "    total_words = len(word_index) + 1\n",
        "    return input_sequences, total_words,word_index\n",
        "\n",
        "inp_sequences, total_words,word_index = get_sequence_of_tokens(puglia)\n",
        "print(\"Sequence: \",inp_sequences[:10])\n",
        "print(\"Total words: \",total_words)\n",
        "print(\"Word index: \",word_index)"
      ],
      "metadata": {
        "id": "Fz0Kzhe6KkBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_padded_sequences(input_sequences):\n",
        "    max_sequence_len = max([len(x) for x in input_sequences])\n",
        "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "    label = ku.to_categorical(label, num_classes=total_words)\n",
        "    return predictors, label, max_sequence_len\n",
        "\n",
        "predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)\n",
        "print(\"Predictors shape:\", predictors.shape)\n",
        "print(\"Label shape:\", label.shape)\n",
        "print(\"Max sequence length:\", max_sequence_len)"
      ],
      "metadata": {
        "id": "YfmeEsfUKvXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we define the 3 parts of the VAE model:\n",
        "\n",
        "* Encoder: first part of the model that serves to create the internal representation of each sequence that arrives. Each input will be transformed into two vectors representing it: mean vector and variance vector.\n",
        "* Sampling: creation of internal input representation\n",
        "* Decoder: for generating new text,dependent on the encoder’s ouput."
      ],
      "metadata": {
        "id": "10Ay1P57ZDDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Lambda, RepeatVector, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "FvZI8IHzckY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = total_words  #vocabulary size\n",
        "embedding_dim = 128      #embedding size\n",
        "latent_dim = 64          #latent vector size\n",
        "max_sequence_len = predictors.shape[1]  #maximum length of the sequences"
      ],
      "metadata": {
        "id": "QQsZNYzhZB3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Definition of the encoder:*"
      ],
      "metadata": {
        "id": "Fid9LyFNZknc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder(max_sequence_len,input_dim, embedding_dim,latent_dim):\n",
        "  inputs = Input(shape=(max_sequence_len,))\n",
        "  # Embedding Layer\n",
        "  x = Embedding(input_dim, embedding_dim, input_length=max_sequence_len)(inputs)\n",
        "  # LSTM Layer\n",
        "  x = LSTM(128, return_sequences=False)(x)\n",
        "  # Parameters of the latent distribution\n",
        "  z_mean = Dense(latent_dim)(x)\n",
        "  z_log_var = Dense(latent_dim)(x)\n",
        "\n",
        "  return z_mean, z_log_var,inputs\n",
        "\n",
        "z_mean, z_log_var,inputs = encoder(max_sequence_len,input_dim, embedding_dim,latent_dim)"
      ],
      "metadata": {
        "id": "3Qn-EGrCctAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Definition of the sampling:*"
      ],
      "metadata": {
        "id": "jWhXqQCKlWUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    batch = K.shape(z_mean)[0]\n",
        "    dim = K.int_shape(z_mean)[1]\n",
        "    epsilon = K.random_normal(shape=(batch, dim))\n",
        "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
      ],
      "metadata": {
        "id": "q1JQ6cNac-ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_vector = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])"
      ],
      "metadata": {
        "id": "sIuTsMKzZVuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*Definition of the decoder:*"
      ],
      "metadata": {
        "id": "WPupzLZigdbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder(latent_vector,max_sequence_len):\n",
        "  decoder_h = Dense(128, activation='relu')\n",
        "  h_decoded = decoder_h(latent_vector)\n",
        "  x_decoded_mean = RepeatVector(max_sequence_len)(h_decoded)\n",
        "  x_decoded_mean = LSTM(128, return_sequences=True)(x_decoded_mean)\n",
        "  x_decoded_mean = TimeDistributed(Dense(input_dim, activation='softmax'))(x_decoded_mean)\n",
        "\n",
        "  return x_decoded_mean\n",
        "\n",
        "x_decoded_mean =  decoder(latent_vector,max_sequence_len)"
      ],
      "metadata": {
        "id": "NoRZAF1gghrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definitive creation of the VAE model:"
      ],
      "metadata": {
        "id": "CukSB9AehJcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vae = Model(inputs, x_decoded_mean)"
      ],
      "metadata": {
        "id": "4hiaTkuahGk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "kl_weight = 0.1\n",
        "\n",
        "reconstruction_loss = K.sum(K.sparse_categorical_crossentropy(inputs, x_decoded_mean), axis=-1)\n",
        "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
        "kl_loss = K.sum(kl_loss, axis=-1)\n",
        "kl_loss *= -0.5\n",
        "vae_loss = K.mean(reconstruction_loss + kl_weight * kl_loss)\n",
        "vae.add_loss(vae_loss)\n",
        "vae.compile(optimizer='adam')"
      ],
      "metadata": {
        "id": "mB4mkZoRh3oF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae.fit(predictors, epochs=150 , batch_size=16, validation_split=0.1)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6BSgO91Lh5Tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_input = Input(shape=(latent_dim,))\n",
        "decoder_h = Dense(128, activation='relu')\n",
        "h_decoded = decoder_h(decoder_input)\n",
        "x_decoded_mean = RepeatVector(max_sequence_len)(h_decoded)\n",
        "x_decoded_mean = LSTM(128, return_sequences=True)(x_decoded_mean)\n",
        "x_decoded_mean = TimeDistributed(Dense(input_dim, activation='softmax'))(x_decoded_mean)\n",
        "\n",
        "decoder = Model(decoder_input, x_decoded_mean)\n",
        "\n",
        "def generate_text(decoder, latent_dim, word_index, max_sequence_len, num_samples=1):\n",
        "    sampled_latent_vectors = np.random.normal(size=(num_samples, latent_dim))\n",
        "\n",
        "    decoded_sequences = decoder.predict(sampled_latent_vectors)\n",
        "\n",
        "    index_word = {v: k for k, v in word_index.items()}\n",
        "\n",
        "    generated_texts = []\n",
        "    for seq in decoded_sequences:\n",
        "        generated_text = ' '.join([index_word.get(index, '') for index in np.argmax(seq, axis=1)])\n",
        "        generated_texts.append(generated_text)\n",
        "\n",
        "    return generated_texts\n",
        "\n",
        "generated_texts = generate_text(decoder, latent_dim, word_index, max_sequence_len, num_samples=5)\n",
        "for i, text in enumerate(generated_texts):\n",
        "    print(f\"Generated text {i+1}: {text}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "in3L7HLkkXQx",
        "outputId": "e330bc9a-173f-44a4-8591-a620bb23f48f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 914ms/step\n",
            "Generated text 1: qual qual qual qual qual qual qual qual coscienza passa passa passa passa passa passa passa passa passa passa passa\n",
            "Generated text 2: qual qual qual qual qual qual qual qual qual qual qual qual qual qual qual qual qual qual qual qual\n",
            "Generated text 3: baci baci baci baci baci baci baci baci baci baci pur pur pur pur pur pur pur pur pur pur\n",
            "Generated text 4: coscienz coscienz coscienz coscienz coscienz coscienz coscienz coscienz coscienz coscienz coscienz coscienz coscienz coscienz coscienz coscienz coscienz coscienz coscienz coscienz\n",
            "Generated text 5: raffaele raffaele raffaele raffaele raffaele raffaele raffaele raffaele raffaele raffaele raffaele raffaele raffaele raffaele raffaele raffaele raffaele raffaele raffaele raffaele\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, not even the VAE model works well for text generation. This is because of the limited data set.\n",
        "As a result, we try to use pre-addressed models."
      ],
      "metadata": {
        "id": "dsjc19Vf9z3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GEMINI-PRO**\n",
        "The first pre-trained model that was used is Gemini-pro via the API offered by Gemini"
      ],
      "metadata": {
        "id": "_DZimRHA9GQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e322UG5S5_nk",
        "outputId": "a674233f-73f2-4c9f-8a1e-ed0792df0fb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.2/164.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.3/718.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Python SDK\n",
        "import google.generativeai as genai\n",
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "bH_pzxNh5ckh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-pro')"
      ],
      "metadata": {
        "id": "2iyJ68KS641r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frasi = df[df['region']=='puglia']['text'][:10].values\n",
        "regione = puglia\n",
        "frasi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "uYnM4dA_AQHv",
        "outputId": "58ebaaed-f3d7-4a54-9461-223dab62b0ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[\\' una grandissima artista barese ci lascia. addio a mariolina de fano. eccola qui che interpreta la vecchie e la mort via \\'\\n \" raffaele, mi sembra che sto\\'parlando con mio figlio. quindi basta dire munnu e\\' munnu sara\\'. mi da fastidio, di chi non vuole collaborare con l\\'italia. \"\\n \\'bbeddhi comu lu sule \\' \\' versione barese. la nonn gastema ! scritto da \\'\\n \" la reazione di mio padre, da incorniciare, come al solito: ma tu vid nu picc, mo t\\'aviva nca! pur sop a la coscienz\\' t\\'avevna tne l sant midc! (trad.: guarda un po\\' che adesso dovevi soffocarti! pure sulla coscienza ti dovevano tenere ermal e fabrizio!) \"\\n \\'na brutta fac\\'\\n \\' accendo la tv, papa guarda la tv, mi guarda: qual d l sant midc aspttam staser? ha gia capito tutto. \\'\\n \\'none e fore te capu\\'\\n \\'un mese sanza de te e gia passato un mese da quando te ne sei annato da qhessa vita ci manchi tanto gigi arrivederci matta\\'\\n \"sei molto bella vieni a trovarmi. qui c\\'e lu vento lu sole lu mare. baci amore mio.\"]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Scrivimi 10 frasi lunghe in dialetto della puglia dammele in csv\""
      ],
      "metadata": {
        "id": "tZuVxGty_N3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(prompt)\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "uNIzJD7e7zLU",
        "outputId": "57f7d50b-6cbf-48de-c4dc-16711699163c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Originale dialettale | Traduzione |\n",
            "|---|---|\n",
            "| \"L'ave capite ca stè scurde 'ngule, uè?\" | Hai capito che sta facendo buio qui, eh? |\n",
            "| \"Quidde uè, u bbène 'na fusse e u ddòmene ammure i' bbramme\" | Quello lì, ti dà una botta e il giorno dopo ti tira le orecchie |\n",
            "| \"S'avìje fattende a u mare, purtatine 'ngule u paste de mandule\" | Se andate al mare, portateci anche i pasticcini di mandorle |\n",
            "| \"U tiembbe dùre u bbène e ddùre u male, sta' sempre luatezze\" | Il tempo dura sia il bene che il male, stai sempre attento |\n",
            "| \"Nun mbi ne scorde ca si' figliu meje, e 'u sange meje scorre 'nd'u core tue\" | Non dimenticare mai che sei figlio mio, e che il mio sangue scorre nel tuo cuore |\n",
            "| \"Acceppette uanne 'u diaule te chiame, e t'embie a ddumandà 'na ssande rrube\" | Accetta quando il diavolo ti chiama, e ti manda a chiedere una santa croce |\n",
            "| \"U ciuane, quanne 'u uede u lupu, s'amminacce a u quaglie e 'u scìppe\" | Il cucciolo, quando vede il lupo, minaccia la quaglia e la prende |\n",
            "| \"A gghie jeu, ca mbi si' runate te 'ssole, ca te vèje sèche a lu sole\" | Io che sono la tua rovina del sole, che ti vedo seccare al sole |\n",
            "| \"Te vuèje bbene, ma cchiù 'nta u core meje ca 'nta a u ccape tue\" | Ti voglio bene, ma più nel mio cuore che nella tua testa |\n",
            "| \"U tiembbe ca trase 'nd'a nu core, lassene 'na cumme cchiù 'nta a nu juore\" | Il tempo che entra in un cuore, lascia una ferita più profonda che in un giorno |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It doesn’t work bad."
      ],
      "metadata": {
        "id": "jfpaaNEY-ZIX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPT-2\n",
        "To get more precision, let’s also try GPT-2.\n",
        "On it is applied a fine-tuning phase for each dialect."
      ],
      "metadata": {
        "id": "76q5oO2DDUX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OokoCwIIEABH",
        "outputId": "320c434c-1f8c-4f39-fa26-ad401c61cce4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.15.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.3.0+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.31.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.5.40)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mCJczhfSFWVY",
        "outputId": "e1516174-b62b-4fce-c236-ed7f303d9ed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.31.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.15.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.5.40)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments, TextDataset, DataCollatorForLanguageModeling\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "regions = df['region'].unique()\n",
        "\n",
        "for region in regions:\n",
        "    region_df = df[df['region'] == region]\n",
        "    texts = region_df['text'].tolist()\n",
        "\n",
        "    train_texts, val_texts = train_test_split(texts, test_size=0.1, random_state=42)\n",
        "\n",
        "    train_file = f'train_{region}.txt'\n",
        "    val_file = f'val_{region}.txt'\n",
        "\n",
        "    with open(train_file, 'w') as f:\n",
        "        f.write('\\n'.join(train_texts))\n",
        "\n",
        "    with open(val_file, 'w') as f:\n",
        "        f.write('\\n'.join(val_texts))\n",
        "\n",
        "    def load_dataset(train_path, val_path, tokenizer):\n",
        "        train_dataset = TextDataset(\n",
        "            file_path=train_path,\n",
        "            tokenizer=tokenizer,\n",
        "            block_size=128\n",
        "        )\n",
        "        val_dataset = TextDataset(\n",
        "            file_path=val_path,\n",
        "            tokenizer=tokenizer,\n",
        "            block_size=128\n",
        "        )\n",
        "        return train_dataset, val_dataset\n",
        "\n",
        "    model_name = 'gpt2'\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "    train_dataset, val_dataset = load_dataset(train_file, val_file, tokenizer)\n",
        "\n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer,\n",
        "        mlm=False,\n",
        "    )\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f'./results_{region}',\n",
        "        overwrite_output_dir=True,\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=4,\n",
        "        save_steps=10_000,\n",
        "        save_total_limit=2,\n",
        "        prediction_loss_only=True,\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        data_collator=data_collator,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    model.save_pretrained(f'./fine_tuned_model_{region}')\n",
        "    tokenizer.save_pretrained(f'./fine_tuned_model_{region}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "j_1i4Rf6EFKG",
        "outputId": "79656b68-f85f-4d3e-ee19-88b1ade3e456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1287' max='1287' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1287/1287 04:01, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>4.809300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>4.353700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='162' max='162' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [162/162 00:29, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [57/57 00:10, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='582' max='582' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [582/582 01:46, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>4.805700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='144' max='144' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [144/144 00:26, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:21, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [96/96 00:17, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='87' max='87' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [87/87 00:15, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 00:04, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [48/48 00:08, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [57/57 00:10, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [48/48 00:08, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9/9 00:01, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [42/42 00:07, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:00, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='69' max='69' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [69/69 00:12, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6/6 00:00, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [36/36 00:06, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [30/30 00:05, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9/9 00:01, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "def generate_sentence(region, input_text, max_length=100, num_return_sequences=1, top_k=50, top_p=0.95, temperature=0.7):\n",
        "    model_path = f'./fine_tuned_model_{region}'\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_path)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
        "\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_length=max_length,\n",
        "        num_return_sequences=1,\n",
        "        top_k=top_k,\n",
        "        top_p=top_p,\n",
        "        temperature=temperature\n",
        "    )\n",
        "\n",
        "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "    return generated_text\n",
        "\n",
        "region = \"valle d'aosta\"\n",
        "input_text = \"ciao\"\n",
        "generated_sentence = generate_sentence(region, input_text)\n",
        "print(generated_sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJlMsvjwFezS",
        "outputId": "313a7917-53b6-45ca-be17-677a85d0bb1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ciao, a former student of the Chinese Communist Party, said that the party's policy of \"reform\" was \"a very serious mistake.\"\n",
            "\n",
            "\"The party's policy of reform is a very serious mistake,\" he said. \"It is a very serious mistake. It is a very serious mistake. It is a very serious mistake.\"\n",
            "\n",
            "The party's policy of \"reform\" is a very serious mistake. It is a very serious mistake. It is a very serious mistake\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After a few attempts, GPT-2 doesn’t work so badly, but it always remains an English-based model and sometimes it doesn’t meet the task and responds in English.\n",
        "So, let’s try to implement a model that has already been fine-tuned for the Italian language"
      ],
      "metadata": {
        "id": "cZt9-KGo_EuJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LLaMAntino-3-ANITA-8B-Inst-DPO-ITA\n",
        "The selected model is **LLaMAntino-3-ANITA-8B-Inst-DPO-ITA** which is a large language model developed for advanced natural language processing (NLP) applications in Italian, such as text generation, machine translation, completion of sentences and answers to questions. Thanks to its 8 billion parameters, it can handle complex tasks and provide more accurate and contextually relevant answers."
      ],
      "metadata": {
        "id": "5dY-YRqOS1Nd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyarrow<15.0.0a0,>=14.0.1\n",
        "!pip install requests==2.31.0\n",
        "!pip install pyarrow >=2\n",
        "!pip install -U transformers trl peft accelerate bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "asoSWIzfX1e8",
        "outputId": "4b7bef24-aed5-4f08-9d64-fd5df3a69ca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: 15.0.0a0,: No such file or directory\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (2024.7.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.42.4-py3-none-any.whl (9.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trl\n",
            "  Downloading trl-0.9.6-py3-none-any.whl (245 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.8/245.8 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting peft\n",
            "  Downloading peft-0.11.1-py3-none-any.whl (251 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-0.32.1-py3-none-any.whl (314 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.1/314.1 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from trl) (2.3.0+cu121)\n",
            "Collecting datasets (from trl)\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tyro>=0.5.11 (from trl)\n",
            "  Downloading tyro-0.8.5-py3-none-any.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.4/103.4 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.4.0->trl)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.4.0->trl)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.4.0->trl)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.4.0->trl)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.4.0->trl)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.4.0->trl)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.4.0->trl)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.4.0->trl)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.4.0->trl)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.4.0->trl)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.4.0->trl)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (13.7.1)\n",
            "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl)\n",
            "  Downloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
            "Collecting pyarrow>=15.0.0 (from datasets->trl)\n",
            "  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->trl)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (2.0.3)\n",
            "Collecting requests (from transformers)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets->trl)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->trl)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (4.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->trl) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\n",
            "Installing collected packages: xxhash, shtab, requests, pyarrow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, tyro, nvidia-cusolver-cu12, transformers, datasets, bitsandbytes, accelerate, trl, peft\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.41.2\n",
            "    Uninstalling transformers-4.41.2:\n",
            "      Successfully uninstalled transformers-4.41.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.32.1 bitsandbytes-0.43.1 datasets-2.20.0 dill-0.3.8 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 peft-0.11.1 pyarrow-16.1.0 requests-2.32.3 shtab-1.7.1 transformers-4.42.4 trl-0.9.6 tyro-0.8.5 xxhash-3.4.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyarrow",
                  "requests",
                  "transformers"
                ]
              },
              "id": "bd4fb8a8fd364d33b5dde11e6383960f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_initial= pd.read_csv(\"NLP_DatasetPrima.csv\")\n",
        "df_prov = pd.read_csv(\"NLP_Dataset_OS.csv\")"
      ],
      "metadata": {
        "id": "IPI8jRU5m-kG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#the model upload\n",
        "\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        ")\n",
        "\n",
        "base_model = \"swap-uniba/LLaMAntino-3-ANITA-8B-Inst-DPO-ITA\"\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_use_double_quant=False,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542,
          "referenced_widgets": [
            "6aee932b6b1d479b947ea8771702f3a8",
            "815cee230a6640edbf803891375700b4",
            "55ece85a64c240cab121ea8d5184ed45",
            "746f2d82a1454d2c91a767ed815218b2",
            "c90c20ea63e3414caf4028beb8a0f729",
            "25cd3ad7ad7a47f98f2fe941b8329adf",
            "18e6df9423ae420ea25cc6af843e7007",
            "e7189a799c2245b7af3c290b4e7daef7",
            "98ad6e39d760496fbed5e25b96522f3b",
            "8f425c61853a42fd8aeb636f19ea97d9",
            "4102d1b6f0734c18adc7471c64bd68aa",
            "980846c9e5894dd6b1f79b281d8e43fb",
            "9204d328741045a58b747f5573a7c849",
            "e04c4cb0236542d8bab0c54d8b06fc6b",
            "0de3fa4f1c8543509296658acf3cbe96",
            "de8ff9ef4f9c439d87245965c48e1ca0",
            "b178fd972a5c45588f02e2d8df09ca79",
            "24da7da5660d479199f84341e76c2712",
            "90f71bf36a364ecb8836960d6e2854c2",
            "719696944c674b2499a78d5b94b189c1",
            "cafe913150d44b65ac68bde068192ca1",
            "abbce3684bf64e66aed7bb1243cf1dd0",
            "8bb44bf66d4c406e91748829ef440622",
            "3be85d5d0d7945f18f58fd67e180f019",
            "d700b8fe50174989b1fe2c7afc244c8c",
            "e8159c40afaa4c11826ed06e5907693d",
            "6f6ebc6a8f664cab8c026afc27989e89",
            "7c7da9802d8840479862b79cc53a001f",
            "66f184051ca942e2876f9aef1ab5bd6c",
            "949b015571ea4ee892fbe393abc0bbe3",
            "43b04ef029344bf0b6e4fd80810f3a73",
            "98120b74432443e3879eebbf5aaef944",
            "8468be408ac84811b547c552ed911f35",
            "6425d60ff0d64062b36996cc97b08d15",
            "6c50b0859a7e4f9eadf7b2116991c32e",
            "713db932d6f74103b1a37402db2e82d8",
            "aa5116c8620e4a3c85455d1f74a2081c",
            "239611a0957d4d59a3c9c3ae7f53d470",
            "c4155864bbd449f584bba13c41f96b23",
            "e4416cab96de405aaeab12b28ddd1d0c",
            "129d61e3b0b044e38d898d12c94d1519",
            "5e51f5f7d0114ed586918b9ca7b72c2a",
            "fd830f5690b54e6cbdbbbd1f3dbde1a7",
            "2eca6b3b27bc41ea86b2b0de956587e8",
            "3b9e630ca3ee461d82944a19aed9ae20",
            "843bbae7eb064709a5017f8b30d95d96",
            "54f4bbb61f104c9fb9fbdc74be920397",
            "660f50380869415eb94fb23b18b9c773",
            "478ce0545d0d4730a663ac7643956ffc",
            "6034a67393f44409931d9e22e8558a70",
            "e19896beeb054504857212b465730dc9",
            "e663a1ac61cd43de96e1584a159d8290",
            "ab15ab94d561400f9cdb9106118ddbb6",
            "5477cc8011d24a8f93316e3f97e964ed",
            "d8280bf75e8a46d2b4b4f77a48673690",
            "90f8d6e87bef4db3b1bf9ec420ab2526",
            "0acd972f4a1a4ebba0a5284bd45af0d8",
            "81c4d2121a2e43be8beaf3b03460af44",
            "e518aa78ad304221833f0848056b6144",
            "cced6aca6fd7485580011adcb96d9d2f",
            "b4d7f42ed82a4a0eb9e90a48fe40a866",
            "2a50393387a64264ab56f8840a1d47da",
            "6cb89e48a29d45399e52c1543f737b7c",
            "2a9b80bc89814daab700a6aa7c0576f2",
            "ec45d9ac466c40458876327dc1cf6ffa",
            "a399bd59d24d4bf7872c679e4efa6e4e",
            "2512e5de4f59426ca7e0aa417a3067d4",
            "48604633ad124d73a902ff60f18c400e",
            "b176a48a5a59498bba6c2269055a35bb",
            "a58f81fa3e3a4de09047d46607b9c9ca",
            "8d40743762c840739b2be56f911bee9c",
            "04d6e9e2ccea42a8af1c09b292f5a635",
            "650df456c7824a2289a8a69652aff4f3",
            "b63e23071a314ebd9cdde076be0f5906",
            "b2cc42e3ee4044bcbdad36c6ca009d19",
            "ae774b02d20a44928dcdbbef2ddc4ac6",
            "7d3d304e04674819b937b5a2f77c52d1",
            "bb73071f009149ad959b2bbd7ec4c531",
            "1d04fee0210e497fba10a4d4da0bec33",
            "323ddca7d9664e1fafb30b907c80c6e7",
            "ece885f1d1b345be9ac7e597139bc5af",
            "bceffb0daa31475c84f69664726f8e6d",
            "e06c9b17e7674a29944c72af5f49d638",
            "673741582b4a46a092070376eba13f4a",
            "672e915869fe43c597e6b8e59f41cae6",
            "39b3e63bcfb74783bc70546b098147f2",
            "394e948f49084d4fa9c48e68dacbe14d",
            "e921f73f6ae84f7e81ca0a7503ff5556",
            "a36898f34584478a99ca7940343cf944",
            "15820a86ff00414a9469385c30acb5a8",
            "0d4be9bd63b34d7ab90cf157f049a9a6",
            "de1fef75dc9640f79b794442f1c88c72",
            "115257e4a52c4d55b68b4b520a8b3075",
            "aef36580656548e48ec3443b83eafcc3",
            "0014ab3b51544f63aec85b941b9c06ff",
            "3489ead55cad473cbb71a25e096a8c4d",
            "a3a67b4e1f8443258328b5bf7b558677",
            "67ce232d10994972b7bd4f1e0dddacc0",
            "3bbfd9448695477894bd65e5ceaeeeea",
            "817a988fe4f6491dbf79402e3a5628a8",
            "a1e38b6e1bc14a85ad047a3438b84bf1",
            "ae4d762dda04487aa82ed0cc0690bee9",
            "693ebde6a3a4489e8b738fc88724c58b",
            "74e71d6245c542d6b08a51e536579024",
            "974b2a1072cb4fbea41a02009700d2d0",
            "4a0913aab07b444ba21d135bb815b4bf",
            "95d41e52868e45e392680d3a8cd35ab8",
            "52eeb3c9036442e8950362fd0a3411ee",
            "b4296561136a42b793868e3f1e0f1f03",
            "f2017185f35e4b01bd38481d6cc0418b",
            "6371103d5f514240b3f3a5624e4b87ca",
            "922833baa7f240cf9d71acfdd7b0d746",
            "8cdc7982013b4ae494f884783b8f741e",
            "d55de7d4a0ca444a931b5dc34886f574",
            "18047eccf09945b485f52fbf673befe5",
            "169aa6ac43364d4a830e7cff66068f01",
            "6be08375e05c461a8e47c417f723295a",
            "130e0f4edbe24bc4b567b2ad2e933c51",
            "a09f8d900e934d2c89cd23265c17165b",
            "26daabe978514dd8bac9710e90c71db2",
            "2caf13bf0c4a482e91ac0c8b89a18e40",
            "31f4e239e7e4419abeb45c0eaca91615",
            "92a45b06f6464aefb7d1d3d0e21a65cd",
            "5f872c8f669a44ca9e2e3cf1484b5bea",
            "305729df068e46a09247a959f5dd797d",
            "efb79297853b4b94b4b906d9a0e89576",
            "3bec6387569448f18bdcbcfab75ea235",
            "f8cd2e92fde94f9d8edf727d67cf8a08",
            "cea35771f4e44add9be2171c762e8a62",
            "c0102a20c8aa4dbbb61d59d6a0c6dfe4",
            "b164c810b8df4fd3aac876383e553a06",
            "4619dc17dd5a4b168dcd4bec7b4c0651"
          ]
        },
        "id": "chGOtHunYZJJ",
        "outputId": "b8e0131c-7c03-4d35-9ba5-96df213dee6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6aee932b6b1d479b947ea8771702f3a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "980846c9e5894dd6b1f79b281d8e43fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8bb44bf66d4c406e91748829ef440622"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6425d60ff0d64062b36996cc97b08d15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b9e630ca3ee461d82944a19aed9ae20"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90f8d6e87bef4db3b1bf9ec420ab2526"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2512e5de4f59426ca7e0aa417a3067d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb73071f009149ad959b2bbd7ec4c531"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/182 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a36898f34584478a99ca7940343cf944"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "817a988fe4f6491dbf79402e3a5628a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6371103d5f514240b3f3a5624e4b87ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31f4e239e7e4419abeb45c0eaca91615"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sys = \"Sei un assistente digitale AI per la lingua dialettale italiana di nome LLaMAntino-3 ANITA.\" \\\n",
        "    \"(Advanced Natural-based interaction for the ITAlian language).\" \\\n",
        "    \" Rispondi imitando il linguaggio con cui ti vengono passate le frasi.\"\n",
        "\n",
        "import transformers\n",
        "pipe = transformers.pipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    return_full_text=False, # langchain expects the full text\n",
        "    task='text-generation',\n",
        "    max_new_tokens=512, # max number of tokens to generate in the output\n",
        "    temperature=0.6,  #temperature for more or less creative answers\n",
        "    do_sample=True,\n",
        "    top_p=0.9,\n",
        ")"
      ],
      "metadata": {
        "id": "ABUBoXjja7dp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = df_initial[df_initial['region']=='puglia']['text'].tolist()\n",
        "prompt = f\"Le frasi delimitate da \\' sono frasi del dialetto di Puglia: \\'{text[0]}\\',\\'{text[1]}\\',\\'{text[2]}\\',\\'{text[3]}\\',\\'{text[4]}\\'.Generami altre 10 frasi del dialetto pugliese. Senza introduzione. Senza elenco puntato\""
      ],
      "metadata": {
        "id": "_z19sgdydJOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": sys},\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "]\n",
        "\n",
        "sequences = pipe(messages)\n",
        "for seq in sequences:\n",
        "    print(f\"{seq['generated_text']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBwpC8jdd1N8",
        "outputId": "c0bf847f-231a-493e-b96a-f9fa07415867"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cu' 'na gran'de pessime notti invernali  \n",
            "Fa difìcile usci' a fa' someje  \n",
            "Munnu ca s'addimmora, s'addimmora  \n",
            "Nn'è cchiù roba a fà, si s'addorme  \n",
            "E ccà ven' a fà dispiacere a mamma  \n",
            "Nn'è 'nu omme ca no' pecca, pecca pure 'o santo  \n",
            "T'aspetta 'a st'anne e t'aspetta 'n'altra  \n",
            "Cchiù mali ca bene, cchiù mali ca bene  \n",
            "Facc' a mme a penza, a mme a penza  \n",
            "Chiddh' ca s'innamora, s'innamora a l'immagine';\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Among the generation models, this is the most suitable. Then, in the next step, we will use LLaMAntino-3-ANITA-8B-Inst-DPO-ITA for generating new sentences."
      ],
      "metadata": {
        "id": "qY_eFVmDosDA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ6fiJMA5AMy"
      },
      "source": [
        "## **OVER-SAMPLING**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_prov = pd.read_csv(\"NLP_Dataset_OS.csv\")\n",
        "print(df_prov.shape)\n",
        "\n",
        "add = {\"text\": [], \"region\": []}\n",
        "\n",
        "regions = ['veneto','lombardia','sicilia','toscana','sardegna','emilia romagna','calabria','puglia','piemonte','liguria','friuli-venezia giulia','marche','abruzzo','umbria','trentino-alto adige','basilicata','molise','valle d\\'aosta']\n",
        "\n",
        "for region in regions:\n",
        "    texts = df_initial[df_initial['region'] == region]['text'].tolist()\n",
        "\n",
        "    random_choose = []\n",
        "    for _ in range(7):\n",
        "      random_choose.append(randint(0, len(texts)-1))\n",
        "\n",
        "    prompt = f\"Le frasi delimitate da \\' sono frasi del dialetto della regione {region}: \\'{texts[random_choose[0]]}\\',\\'{texts[random_choose[1]]}\\',\\'{texts[random_choose[2]]}\\',\\'{texts[random_choose[3]]}\\',\\'{texts[random_choose[4]]}\\',\\'{texts[random_choose[5]]}\\',\\'{texts[random_choose[6]]}\\'.Genera 80 frasi del dialetto di {region}.Senza introduzione. Senza elenco puntato.Senza righe vuote. Termina ogni frase con \\n.\"\n",
        "\n",
        "    print(prompt)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": sys},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "\n",
        "    sequences = pipe(messages)\n",
        "\n",
        "    for seq in sequences:\n",
        "        generated_text = seq['generated_text']\n",
        "        print(f\"{seq['generated_text']}\")\n",
        "\n",
        "        # Split phrases into separate rows (if necessary)\n",
        "        if \"\\n\" in generated_text:\n",
        "            phrases = generated_text.split(\"\\n\")\n",
        "            add[\"text\"].extend(phrases)\n",
        "            add[\"region\"].extend([region] * len(phrases))\n",
        "        else:\n",
        "            add[\"text\"].append(generated_text)\n",
        "            add[\"region\"].append(region)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qk5CsF4Ofo7D",
        "outputId": "d119d285-4398-4708-d5c3-6819f8b2c62f",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(415, 2)\n",
            "Le frasi delimitate da ' sono frasi del dialetto della regione veneto: 'chirurghi ingenieri economisti..ma allora qui cosa ci farebbe... ma va a ciapa' i ratt ebete','vacca varda che mutande onte che te ghe',' in veneto popolo c'e un proverbio che dice sta lontan dal culo del mulo, dal dente del can e da chi ga sempre la corona in man ','abbiamo iniziato a studiare il caso di brendola. 'dio come queo dea cisterna'','mi aspetto 5 6 7 8 9 .....69...quea xe 'na bea giornata ... bon pomeriggio','spriz seletct ovvero spriz veneziano','e quindi e quello che dicono pure loro. forse per voi e troppo bassa la stima, aspettiamo che arrivi al 50% di furbi per dire che fatto cosi il rdc e na boiata.'.Genera 80 frasi del dialetto di veneto.Senza introduzione. Senza elenco puntato.Senza righe vuote. Termina ogni frase con \n",
            ".\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "qua ghe é poca pazienza. \n",
            "femmo un errore in calcolo, in calcolo se el ghe dà ancona. \n",
            "tuti i dì a cason, no i dì de tuti i cas. \n",
            "e ghe é invidio a el che ghe cate in man. \n",
            "mi dispiace no ghe é in cà. \n",
            "a quei de vent'anni no ghe interessa. \n",
            "in veneto dìo no ghe aiuta el fio a no farghe el male. \n",
            "in sta sità no ghe é on in post. \n",
            "l'om che ga no dòpia no ghe conpede el dòpio. \n",
            "tornè in cà con le man in stà. \n",
            "el ze un om che no ghe caza in testa. \n",
            "ghe dispiace ma no ghe é in ofisa. \n",
            "no ghe é bon in sti dì de inverno. \n",
            "in sti momenti no ghe é on in stado de espirito. \n",
            "ghe dispiace no ghe é in storicin. \n",
            "l'om che ga no respeto pae el fio. \n",
            "tornemo in cà co la fame in stà. \n",
            "no ghe é bon in sta caza. \n",
            "el ze un om che no ghe caza in sè. \n",
            "a quei de quarant'anni ghe conpede el tempo. \n",
            "el no ghe capiss, no ghe capì, no ghe capirà. \n",
            "in sti momenti no ghe é on in pace. \n",
            "in sta caza no ghe é on in ordre. \n",
            "a quei de trenta ghe conpede el matrimonio. \n",
            "ghe dispiace no ghe é in ofisa, ghe dispiace no ghe é in cà. \n",
            "el ze un om che no ghe caza in stòrico. \n",
            "el ga no rispetto pae la fame de sò fio. \n",
            "el no ghe capiss, no ghe capì, no ghe capirà el calcul. \n",
            "in sti momenti no ghe é on in solitario. \n",
            "el ze un om che no ghe caza in testa el guadagn. \n",
            "el no ghe caza in stà el\n",
            "Le frasi delimitate da ' sono frasi del dialetto della regione lombardia: 'nel minestrone ci sta bene la parte posteriore insieme alle croste di parmigiano 36 mesi. viene 'na bomba... si vede che sei proprio bauscia caro il mio ezio','sei giorni sulla sette che triturano i maroni con il pd e le sue pippe ora arrivano ius soli con cuperlo bindi bertinotti il futuro.....pazzesco','romina, ma va' a ciapa i ratt! che cosa immonda, dio mio.','bravo gnaro','lo so. ci voleva un ibra adesso a prendere a sberloni tutti negli spogliatoi. non sono schiappe, e la testa che devono accendere...','ma andate a ciapa i ratt!!',' sarebbe un grande gesto di democrazia dopo aver dato la parola a dargli il benservito con un popolare va a ciapa i rat . per mi mancano ormai le parole. '.Genera 80 frasi del dialetto di lombardia.Senza introduzione. Senza elenco puntato.Senza righe vuote. Termina ogni frase con \n",
            ".\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Casa nostra aér sempre stada bella, \n",
            "in borsa a gh'ha quaj, in test a gh'ha men, \n",
            "e l'altro, quell' là, a l'é staccade, \n",
            "anca quand a l'é tornà, a l'é staccade. \n",
            "E in general a gh'hév un'altra idea, \n",
            "el, quell' là, el gh'ha la sò, \n",
            "e in cör a l'é un disaccord, \n",
            "el, quell' là, el s'aspettava l'alter. \n",
            "A l'é stada una giornada inutil, \n",
            "con in fin a l'ha fà pòv, \n",
            "e l'altr a l'é andà via, \n",
            "e mì a gh'ho da pensà a l'altro dì. \n",
            "A gh'é un'ora in la settimana, \n",
            "in la domenega, a gh'é un'ora, \n",
            "che mì a gh'ho da passà in ver, \n",
            "senza 'n not, senza 'n sorris, \n",
            "in ver, in ver, senza 'n pens, \n",
            "a gh'é un'ora, a gh'é un'ora, \n",
            "in la domenega, a gh'é un'ora. \n",
            "In cà a gh'é un gran disord, \n",
            "e mì a gh'ho da dà un'ord, \n",
            "ma el mè fradèl, \n",
            "el no 'l vèl, el no 'l vèl, \n",
            "el no 'l vèl, el no 'l vè, \n",
            "el no 'l vè, el no gh'é, \n",
            "el no gh'é, el no gh'é più, \n",
            "però mì a gh'ho da dà, \n",
            "però mì a gh'ho da dà un'ord, \n",
            "e a gh'é speranza, \n",
            "che mì a gh'ho da dà in manera, \n",
            "che el mè fradèl, \n",
            "el vèl, el vè, el vè, \n",
            "el vè, el vè, el dà, \n",
            "el dà, el dà, el dà in man, \n",
            "el dà in man, el dà in man a mì, \n",
            "in man a mì, in man a mì a gh'ho, \n",
            "a gh'\n",
            "Le frasi delimitate da ' sono frasi del dialetto della regione sicilia: ' lei chiede di esplicitare nel ristretto spazio di un twitt il renzipensiero , un'impresa titanica per cui sono impreparato. diciamo che mi baso sulle risultanze di una osservazione basata sul metodo scientifico, ma facciamo cosi, stamu o viriri e, a cose fatte, ci riaggiorniamo ','in estate comunque il caldo stavo un po' piu serena adesso mi e ricominciata l'ansia camurria','idda e','stannu supra a minchia a tutti','non mi meraviglio di niente. conte u tintu s'addubba di scudetti ma in champions fa schifu','nuddu si pigghia s'un s'assumighia merdacce','oggi c'e il bis carusi!'.Genera 80 frasi del dialetto di sicilia.Senza introduzione. Senza elenco puntato.Senza righe vuote. Termina ogni frase con \n",
            ".\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ci sunnu dui còppoli di sora. \n",
            "C'è chi si fa diri cchiù di cio ch'è. \n",
            "E cc'è chi nun si move un caosso. \n",
            "Sto a virdi comu si va a finiri. \n",
            "Ntra li strata non si canta a tuttu. \n",
            "A l'anniversariu d'un'anni ancora, \n",
            "Stu pizzu di pioggia si sposta a sinistra. \n",
            "Cchiù male di chiddu ca nu joca. \n",
            "Nun è a vera la mumentanza. \n",
            "E cc'è chi si fa diri ca va a céntru. \n",
            "Cchiù curiosu di chiddu ca sta a jazzi. \n",
            "Ntra l'acqua non si bagna a tè. \n",
            "C'è chi si spasa a l'aria. \n",
            "Stu mari di sabbia si muove a nisciuna parti. \n",
            "A l'omu s'addubba di falliri. \n",
            "Nun si canta a l'ora di sè. \n",
            "Stu còppolo di sora si sposta a l'ovirri. \n",
            "E cc'è chi si fa diri ca va a scola. \n",
            "Ntra li strata non si camina a tuttu. \n",
            "Cchiù stortu di chiddu ca si fa diri. \n",
            "Nun è a vera a sincerità. \n",
            "Stu pizzu di pioggia si sposta a sinistra. \n",
            "Cchiù pazzi di chiddu ca si fa diri. \n",
            "E cc'è chi nun si muove un passu. \n",
            "A l'omu s'addubba di mali. \n",
            "Stu mari di sabbia si muove a nisciuna parti. \n",
            "Ntra l'acqua si bagna a pochi. \n",
            "Cchiù cchiù male di chiddu ca nu joca. \n",
            "Nun si canta a l'ora di sè. \n",
            "Stu còppolo di sora si sposta a l'ovirri. \n",
            "Cchiù stortu di chiddu ca si fa diri. \n",
            "E cc'è chi si spasa a l'aria. \n",
            "A l'anniversariu d'un'anni ancora, \n",
            "Stu pizzu di pi\n",
            "Le frasi delimitate da ' sono frasi del dialetto della regione toscana: 'boooo com'e bravo ir mi bimbo. mi fa pure le foto ar buo der culo.','trump fu eletto ! il piacione di foggia passava da quelle parti !!!! cara fetecchia di giornalista',' si e costituito un nuovo gruppo parlamentare: europeisti maie centro democratico. alias raccattaticci con le pezze al culo ma nessuno ha il buon gusto di mandarli a fc? sono sempre piu favorevole ad elezioni. ','marco non rubarmi le battute. ho un'idea cmq, sabato prossimo meeting a casa di andre, lui cucima e noi magnamo?',' come dice il saggio: come fai, sbagli ed e proprio vero, tutti che si lagnano, ma magnateve na cosetta e state boni. ','ah, dimenticavo. di quella decisiva con la giuve ascoltai solo il risultato per radio a roma, al parco di villa pamphili. allora le giornate decisive non le trasmettevano, ma al mio grido d'esultanza una matura signora mi chiese: icch'e glie successo, s'e vinto lo scudetto?','o matonna...andavamo al mare! ci aspettavano du tope!!!'.Genera 80 frasi del dialetto di toscana.Senza introduzione. Senza elenco puntato.Senza righe vuote. Termina ogni frase con \n",
            ".\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mi piace andare a spassarmi a san casciano. \n",
            "il pizzico di pepe fa la differenza, in generale. \n",
            "io non ci vado, a quell'incontro, chè non è il mio genio. \n",
            "il mio compagno di scuola, è andato in banca, in seguito. \n",
            "come si chiama, il ristorante, là in piazza, dove mangiavamo, una volta? \n",
            "in quel giorno di pioggia, non ne valeva la pena, uscire. \n",
            "se no, gli davo un calcio, al suo progetto, naturalmente. \n",
            "a mezzogiorno, andiamo a mangiare, in famiglia, sempre. \n",
            "in campionato, a siena, il nostro club, non va più, in su. \n",
            "è inutile, discutere, con chi non vuole, ascoltare. \n",
            "io non so, il nome, del ristorante, là in piazza, dove mangiavamo, una volta. \n",
            "è un'ingiustizia, non dar nè un minuto, di tiro, al giovane. \n",
            "se non è disponibile, il mio amico, non posso, andare. \n",
            "il mio nonno, non era un grande, amante, del traffico. \n",
            "io non ci andrò, al suo matrimonio, chè non lo conosco, in generale. \n",
            "è inutile, cercare, la moneta, per la fitta nebbia, di un discorso. \n",
            "non è un problema, se non beve, il caffè, il mio amico. \n",
            "il mio cane, non è un grande, amante, del bagno, d'acqua. \n",
            "non ci sto, in questo, tipo di discorso, non m'interessa. \n",
            "se non è disponibile, il mio amico, andrò con un altro, in ogni caso. \n",
            "in quel giorno, di sole, era un giorno, molto, bello, in verità. \n",
            "è inutile, discutere, con chi non vuole, riconoscere, l'errore. \n",
            "il mio nonno, ci portava, in macchina, al mare, in estate. \n",
            "se non è in grado, di capire, non discuto, con lui\n",
            "Le frasi delimitate da ' sono frasi del dialetto della regione sardegna: 'ciao di a bolli biri in zu concheddu miu','donna sarda mi dispraghidi ma deu seu... femmina sarda!! sarda, barrosa, pottu coru, crabeddu e anima! seu terra, soi, bentu e mari ma puru perda, unu nuraghe e, chi ci scudisi, scudisi e ti squartarasa beni a terra! poesia di sandra giglio karma_r','morata coddari unu pei','anche perche sbagli si scatena l'inferno del: a narrede ca non cumprennese nudda, mancu abba in su mare agatasa. tratto da una storia vera','ciao di a bolli biri in zu concheddu miu','bellissima puntata di ulisse dove anche alberto angela stava per dire: cazz' e bentu',' no cretto chi una limba pretzisa pro tottu appet una fotza gai manna de nos muntenner gai unidos, est bellu invece chi ognunu faeddet sa sua, ca sa cosa bella de su sasdu est chi movvendedi dae idda at un attera idda cambiat su faeddu e sa sonantza, est giustu gai. '.Genera 80 frasi del dialetto di sardegna.Senza introduzione. Senza elenco puntato.Senza righe vuote. Termina ogni frase con \n",
            ".\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S'omini a sos montes si dementan cun sa soli. \n",
            "Su tempus passadu est unu in su presente cun sa memoria. \n",
            "Su mari nostru est unu mare de poesia e de guerra. \n",
            "S'omini de su passadu si nchirchjan in su sardu a cuncordu. \n",
            "Unu s'omini s'arrussolu in su sardu cun sa mamma. \n",
            "Su logudoresu est unu logu de sa bellezza e de sa cultura. \n",
            "S'omini a su monte si nchirchjan in su sardu a cuncordu. \n",
            "Sa limba sarda est unu patrimmoniu vivu e dinàmigu. \n",
            "Sa giuventù sarda est unu focu de passione e de lotta. \n",
            "Su sardu est unu limba chi si cumprende cun su cuore. \n",
            "Sa cultura sarda est unu patrimmoniu a tutta sa umanidade. \n",
            "Su nuraghe est unu monumentu a testa de s'omini. \n",
            "Sa poesia sarda est unu cantu a su ventu e a su mari. \n",
            "S'omini a su mare si lassant in sa contemplazione. \n",
            "Sa saidea sarda est una limba chi si faet vivu. \n",
            "Unu s'omini si lassat in sa saidea sarda. \n",
            "Sa limba sarda est unu sigulu de identidade. \n",
            "S'omini a su monte si nchirchjan in sa saidea sarda. \n",
            "Sa saidea sarda est unu patrimmoniu a tutta sa sarda. \n",
            "Sa poesia sarda est unu cantu a su coru e a su sardu. \n",
            "Sa limba sarda est unu caminu de comunicazione. \n",
            "Sa cultura sarda est unu patrimmoniu a tutta sa umanidade. \n",
            "Su sardu est unu limba chi si cumprende cun su coru. \n",
            "S'omini a su mari si lassant in sa contemplazione. \n",
            "Sa saidea sarda est una limba chi si faet vivu. \n",
            "Su logudoresu est unu logu de sa poesia e de sa guerra. \n",
            "Sa limba sarda\n",
            "Le frasi delimitate da ' sono frasi del dialetto della regione emilia romagna: 'andrea mingardi - sfighe via auguri andrea mingardi !noi bolognesi ti amiamo tanto..80 anni ,pero.t'amper ancoura un cinno..','te lo dico ner tuo dialetto, in bocca ar lupooooo!!!!!','da noi in romagna si dice darsi le martellate sui maroni per fare dispetto alla moglie. io non mi augurerei mai la vittoria delle destre...','da sborone del mondo a patetico bimbo capriccioso e viziato. e da emulatore politico dello sborone in italia a suo ()...mamma mia che brutta fine entrambi!','e esattamente il senso del chi non si vaccina fora dae bae','pigiama azzurrino e vestaglia maron','gna a fa l'afa ... gna a fa proprio !'.Genera 80 frasi del dialetto di emilia romagna.Senza introduzione. Senza elenco puntato.Senza righe vuote. Termina ogni frase con \n",
            ".\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Te ghe dago un pò de riezendo, ma i mei informitec no gh'a da rispond' in sti mod, ma in stiò, cioè bene, per dir....  \n",
            "Al dì d'incò, i mei nonno no s'aspettava de veder un ragazzo che se ten sù col smartphone tutta la giornata, e no con l'aria di capir gò.  \n",
            "No i andò a la mossa in piazza, al sè a la mossa in rete, e in vece de far un pa de cal, fa un pa de dito virtuoso col like e col comment.  \n",
            "E ghe vegn anca un tipo de rabbia, quél che no s'accorda de no vèser sèguito, de no vèser còlto.  \n",
            "I mei cugnà, lu s'è mess a studia' l'informatiga, e adess a l'è in gara con i giovane, in vece de caccia in montagna.  \n",
            "I mei zite, le s'aspettavaan de veder un marid in gh'arma, e no in tuta quèlla roba de moda.  \n",
            "Ghe vegn anca un tipo de rassurn, quél che s'aspetta de vèser sò, de vèser aspetà.  \n",
            "In campagn, al è più bel in auton, quand i camp è verdi e i frut è matur.  \n",
            "No i gh'è anma, che andè a fa un giret in bicicleta, senza un ascolt a un bell sò.  \n",
            "E ghe vegn anca un tipo de inghjot, quél che s'inghjòt in guèra con i sò, con la sò, con la vita.  \n",
            "I mei pare, lu s'è sempre dìto contrari a la moto, e adess a l'è in gira a ped, senza un motor.  \n",
            "In panpera, i gh'è anma, che s'aspetta de vèser servì, e no de vèser in servit.  \n",
            "Gna a va a caccia, gna a va a fa l'afa\n",
            "Le frasi delimitate da ' sono frasi del dialetto della regione calabria: 'sugnu u toi capitanu, merdaaaa',' mio padre mi ha insegnato che ogni opinione va rispettata e... camina ccu ri megghjiu e impara camina ccu ri peiju e sparta morale?vediamo se capite ','in calabria ti volti un attimo...e trovi na sazizza sulla scrivania!','ahahah approvata pienamente troppo bella e poi ci vo na fabbrica i prolung','il nostro caro sindaco e cchiu munnizza i chira ca c'e au palakro','fisso a 15 euro ovviamente e compresa n'insalata i pimmadduari cu cipuddra e u tartufo di pizzo. riprenderemo il viaggio intorno alle ore 15:00 tagliamu e jamu ara sila. offriremo panini cu sazizza da mangiare sul lago. ni ricoglimu in serata . passeremo una giornata diversa.','fimmina juventina calavrise'.Genera 80 frasi del dialetto di calabria.Senza introduzione. Senza elenco puntato.Senza righe vuote. Termina ogni frase con \n",
            ".\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S'aspettau ca veni,. \n",
            "S'ha ditatu ca a sera andàmu a mangià,. \n",
            "Caminàmu ccu la famiglia e andàmu a Pizzo,. \n",
            "C'è statu un bellu sole a Pizzo,. \n",
            "Faccimu a merenda a Pizzo,. \n",
            "Un caffè e na pasticca,. \n",
            "Sti notti d'inverno,. \n",
            "S'ha presu un cassetto di ciavuramedda,. \n",
            "Mio fratru e andatu a Crotone,. \n",
            "S'ha dettu ca a Crotone c'è statu un bellu mercatu,. \n",
            "L'acqua di Sparta,. \n",
            "Faccimu a spasso a Sparta,. \n",
            "Caminàmu pe' i sentieri,. \n",
            "S'ha vistu un bellu panorama,. \n",
            "Fimmina juventina calavrise,. \n",
            "Mio zio e andatu a Reggio,. \n",
            "S'ha dettu ca a Reggio c'è statu un bellu mare,. \n",
            "Caminàmu a mare,. \n",
            "M'ha datu un baghjettu,. \n",
            "S'ha perdu a chiavetta,. \n",
            "Faccimu a cercà,. \n",
            "Mio patri e ditatu ca a vita e lunga,. \n",
            "S'ha dettu ca a vita e bellu,. \n",
            "S'aspetta a primavera,. \n",
            "S'ha ditatu ca a primavera e vicina,. \n",
            "Faccimu a festa,. \n",
            "S'ha mangiato a panu ca'zu,. \n",
            "Mio fratru e andatu a Cosenza,. \n",
            "S'ha dettu ca a Cosenza c'è statu un bellu museu,. \n",
            "Caminàmu a museu,. \n",
            "S'ha vistu un bellu pittura,. \n",
            "M'ha datu un sorrisu,. \n",
            "S'ha dettu ca a sorrisu e bellu,. \n",
            "S'aspetta a sera,. \n",
            "S'ha ditatu ca a sera e bella,. \n",
            "Faccimu a pasce a cani,. \n",
            "S'ha datu a cani un bocconc,. \n",
            "\n",
            "Le frasi delimitate da ' sono frasi del dialetto della regione puglia: 'e con a studiare in salento lu viento lu sole e lu mare?','ti sei messo la come la mummia ti facevi bacia....a fatt u strunz che ricordi!!!','a ci fatica na sarda. a ci non fatica doi',' ehm... c facc d caz sarebbe cosi: ma chiamind c facc d cazz ca ten cuss! (guarada che faccia di caxxo ha questo) nel caso di gauss e per dire che carino . ci sono altre accezioni negative. ','basta teorie cospirazioniste avete stancato, e na cippa !!! invece di fare retorica, scendete in politica mette i la faccia e le palle per costatare oppure limitare lo strapotere come ha fatto il m5s e non la lega ladrona oppure fratelli coltelli.','ussignur, ha bloccato me, mai interagito, sara una novax, nocovid, na scem insomm','non ridere mentre fai la riunione se no ri sgamano.'.Genera 80 frasi del dialetto di puglia.Senza introduzione. Senza elenco puntato.Senza righe vuote. Termina ogni frase con \n",
            ".\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cu mme so' andatu a Poggioreale a festa, ma a minchia so' stata a l'auto in riparazzione. \n",
            "Cosa faje a sera quand'è caldo e nu viento 'nfurna a finestra. \n",
            "A maje a dispiaccie pe' chidd'ha pecato, ma a maje a dispiaccie pe' chidd'ha sofruto. \n",
            "S'è andatu a San Vito a caccia, ma a tornatu a manda a dì a maje ca n'ha caccato niente. \n",
            "Mare e sole d'inverno no' s'arriprende, a se'mpiede a neve. \n",
            "A cchi a dice ca a so' intelligent, a cchi a fa ca a so' intelligente. \n",
            "A maje a diri ca a so' stata a casa, ma a maje a menti ca a so' stata a mare. \n",
            "Cosa faje a feste se no' t'aspetta a nisciuna a persona. \n",
            "A maje a diri ca a so' felice, ma a maje a so' cchi a soffre. \n",
            "A se' a scappato a scola, a se' a ristretto a casa a nun a fà nudda. \n",
            "Femma pugliese ca se fa a cullà a putijiele, a nun se fa a cullà a figliuole. \n",
            "S'è a messu a la polizia, a l'han a dì a maje a nun faje a cchi a. \n",
            "A maje a diri ca a so' a bona persona, ma a maje a faje a cchi a cattiva azione. \n",
            "Mare e sole d'estate s'arriprende, a se'mpiede a canicchia. \n",
            "A maje a diri ca a so' a persona onesta, ma a maje a tien a pecche a nascondite. \n",
            "A se' a dispiaccie pe' chidd'ha pecato, a se' a dispiaccie pe' chidd'ha sofruto. \n",
            "Cosa faje a sera quand'è freddo e nu viento 'nfurna a finestra\n",
            "Le frasi delimitate da ' sono frasi del dialetto della regione piemonte: 'piciu si nasce lui lo nacque','e tu chi cazzo sei che cazzo vuoi sei mai uscito dal italia ?? na va fanculo strunz e merda','toh, il babaciu ne ha tirata fuori un'altra.','ho letto l'articolo e non ci ho capito una cippa. mi tengo i batteri e bon','spotify na zappa de nulla non funziona na ceppa qui','nello specifico ciula is megl che uan','magnato abbiam magnato!'.Genera 80 frasi del dialetto di piemonte.Senza introduzione. Senza elenco puntato.Senza righe vuote. Termina ogni frase con \n",
            ".\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C'a l'è 'na giornada da nebbia. \n",
            "Cò, a me pare che 'l è inùtil. \n",
            "Quel pô, a me l'ha dit a 'l amich. \n",
            "In montagna a l'è più bel in autùn. \n",
            "L'è andà a caccia e ghe l'ha portà 'n conig. \n",
            "A me l'ha detto e a me l'ho credìü. \n",
            "E tu, a gh'è rivisto quell'om? \n",
            "A gh'è un'oca, a gh'è un'oca grande. \n",
            "A me l'ha dato 'n pom in regalo. \n",
            "Ghe l'ha detto a la sò mère. \n",
            "A me piace la polenta cun la lard. \n",
            "Quel pò, a l'è andà a lavorà. \n",
            "La mè sore a l'ha fà la crosa. \n",
            "In pian a l'è più cald d'in mont. \n",
            "L'è andà a scola e a l'ha portà 'l quadern. \n",
            "A m'hò detto e a m'ho cremej. \n",
            "Quel pô, a l'è andà a gara. \n",
            "Ghe l'ha dat a la sò fia. \n",
            "Cò, a m'hò dito a mì. \n",
            "A m'hò scrit 'na lètra a mì. \n",
            "L'è andà a còll a l'è rivà tard. \n",
            "A m'hò detto a mì stess. \n",
            "L'è andà a festa e a l'è tornà 'n ora tard. \n",
            "In autùn a l'è andà a caccia. \n",
            "A m'hò mangià 'n panett cù. \n",
            "Quel pô, a l'è andà a scuola. \n",
            "Ghe l'ha dat a sò fradèl. \n",
            "A m'hò detto a m'hò credìü. \n",
            "Cò, a l'è inùtil ch'a vaga. \n",
            "Quel pô, a l'è andà a festa. \n",
            "A m'hò fà 'l baghèt a mì. \n",
            "L'è andà a còll e\n",
            "Le frasi delimitate da ' sono frasi del dialetto della regione liguria: 'cumme te bella zena','genitori abbelinati i dobermann vanno addestrati fin da piccoli','a ne ghe credo ancoa','belin che pippe...goal regalato','io parlo solo zeneize ovvio quandu me capiscian bungiurnu','datemi della troglodita razzista, ma chi sono questi che hanno votato 'sta cosa inguardabile e inudibile? (come si dice a zena..) me tastu se ghe sun!','ce ne sono ancora tanti che li voteranno grazie alle belinate pazzesche che scrive il loro giornalista preferito, colui che condanna prima che vengano fatti i processi e le condanne o assoluzioni quelle vere.'.Genera 80 frasi del dialetto di liguria.Senza introduzione. Senza elenco puntato.Senza righe vuote. Termina ogni frase con \n",
            ".\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A l'è pronta a partì, ma no con la giusta velocità. \n",
            "No, i zeneize, no i toscanelli, no i piemontesi, no i lombardi, ce n'è un pò de cummicò in ogni còrsa, ma in zena, in zena, ce n'è de più. \n",
            "A me pare che i lòscen, i stava a dàit, a no ghe dàian còssa. \n",
            "E gh'è anmò chi, in sti moment, cred a 'na vittoria, a no la ved anmò l'àtera còrsa. \n",
            "A no m'aspettava 'na difesa sò tanta, ma a l'è stada miga bona, miga bona. \n",
            "E in sti moment, chi gh'è a fà l'analisi politica, a no la fa miga ben. \n",
            "In Liguria, in Liguria, a no gh'è anmò tanti de i nosti, ma a gh'è anmò zeneize, a gh'è anmò rivierasche, a gh'è anmò ponfierasche, a gh'è anmò camoglisce. \n",
            "Ghe penso, a no gh'è stada fàita giusta giusta giusta, a l'è stada fàita a scapèl, a l'è stada fàita a cazz, a l'è stada fàita. \n",
            "A l'è stada fàita a dàit, a no gh'è stada fàita a man, a l'è stada fàita. \n",
            "In sti moment, chi gh'è a dir \"a va bèn\", a no l'ha capito, a no l'ha capito, a no l'ha capito. \n",
            "A no gh'è stada fàita a favoei, a l'è stada fàita a scapèl, a l'è stada fàita a cazz. \n",
            "A l'è pròpri, a l'è pròpri, a no gh'è anmò alter, a l'è pròpri. \n",
            "Ghe è anmò chi, in st\n",
            "Le frasi delimitate da ' sono frasi del dialetto della regione friuli-venezia giulia: 'vajont 9.10.1963 vicinanza e solidarieta' alla comunita' di vajont, erto e casso, longarone, ponte nelle alpi. alle famiglie che hanno perso i loro quasi 2000 cari. non abbiamo dimenticato! na tragedijo vajonta, na skoro 2000 mrtvih in na rano celotne skupnosti ne bomo pozabili!','bandiere gavemo??? ','la me tera xe seca incandia, sento i ossi che se desfa come gesso, i lavari crepa, go sen. me impienaria de vin e andaria pissare sui ponti de la brenta , del po, un getto de acqua, na cascada che impenisse el leto, spenze indrio el mare, onze la tera.','con convinzione, rappresentando il comune di aiello, a gorizia e nova gorica, per i diritti di tutti, pravica za vse...','bon stasera te se sfoghi','chi che no varda la lodovini, dio ghe cava anca teleelefantino.',' ti sconti ogni binore, e quant che tu saludis i furlans cun mandi mi sint part dal to mond. une furlane a trieste jo e un furlan a rome tu. e love '.Genera 80 frasi del dialetto di friuli-venezia giulia.Senza introduzione. Senza elenco puntato.Senza righe vuote. Termina ogni frase con \n",
            ".\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Na val de sere, in mont, i stoni s'incavetin. \n",
            "Ti aspietas, invar, el dì che tu vns return. \n",
            "No ghe faltà, in cal, un bèl caldèl. \n",
            "La me nona, in primavil, la fa i fior. \n",
            "I pont, in brenta, i dà an impression forte. \n",
            "Gnûf, in stadi, no ghe é più spati. \n",
            "La me gera, in famee, la fa la cuina. \n",
            "No varda, in te, el so stacai. \n",
            "Ti speri, in un dì, el so return. \n",
            "Un pò, in più, un gò, un sorriso. \n",
            "I furlan, in trieste, i stùdies. \n",
            "La me sore, in foto, la rassembra. \n",
            "Na gior, in esté, la fa calda. \n",
            "No t'aspieta, invar, el dì che tu partis. \n",
            "Un pò, in cal, un bèl caldèl. \n",
            "Ti saludi, in scrit, un caro salut. \n",
            "La me vita, in trieste, la s'è fata. \n",
            "Un gò, in più, un pò de son. \n",
            "I cim, in mont, i s'incavetin forte. \n",
            "La me nona, in cuina, la fa i gnocj. \n",
            "Ti vns, invar, a vns return. \n",
            "No ghe varda, in te, el so sorriso. \n",
            "La me gera, in famee, la fa la menù. \n",
            "Un pò, in più, un pò de pace. \n",
            "I furlan, in rome, i stùdies no. \n",
            "La me sore, in gial, la rassembra. \n",
            "Na gior, in sté, la fa calda. \n",
            "La me vita, in rome, no s'è fata. \n",
            "Un gò, in più, un sorriso de rire. \n",
            "I pont, in friûl, i dà an impression. \n",
            "Ti speri, in un dì, el so ajùt. \n",
            "No t'aspieta, invar, el dì che tu venis\n",
            "Le frasi delimitate da ' sono frasi del dialetto della regione marche: 'buongiorno belle anime festa della candelora dall'inverno semo fora','due perche il pomeriggio c'e l'abbiocco',''nfatti porello oh!!!','ehehhehehvero fra!!!puo darsi era svenuto morto cadavere e noi?????non siamo venuti in tuo soccorso verissimo fra tropp o ver','porca puttena agg fatt gol!!!!','e chiamiamolo abbiocco ! i sicuro li vicino nun s abbioccherebbe nessuno','ecche sto qua a pettina le bambole?'.Genera 80 frasi del dialetto di marche.Senza introduzione. Senza elenco puntato.Senza righe vuote. Termina ogni frase con \n",
            ".\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Semo andati a festa la notte e me l'ha detto il fratellino. \n",
            "Santo cielo che era stanco d'aspettare. \n",
            "C'è l'uva e ce n'è de poco. \n",
            "Fosse stato mio fratello ce l'avria detto. \n",
            "L'ho vista la mia cugna a Sant'Egle. \n",
            "Semo andati al mercato in due. \n",
            "Invece de andare al cinema s'è andato a casa. \n",
            "Me l'ha detto la sorella che c'era la festa. \n",
            "Semo partiti alle 7 e s'è fatto giorno in cielo. \n",
            "L'ha detto lui che non c'era la macchina. \n",
            "Semo stati a casa tutta la giornata. \n",
            "L'ho conosciuta a Sassoferrato. \n",
            "L'ha detto lui che era inutile. \n",
            "Semo stati in paese e non c'era nudda. \n",
            "L'ha detto la mamma che era stanco. \n",
            "Semo stati a fare la spesa con la mamma. \n",
            "Era stanco d'aspettare il suo amico. \n",
            "Semo stati in biblioteca a studia. \n",
            "Invece de andare a casa s'è andato a fare un giro. \n",
            "Me l'ha detto il fratello che non c'era. \n",
            "Semo stati a fare un giro in paese. \n",
            "Semo stati a casa in due. \n",
            "L'ha detto lui che era un'ora. \n",
            "Semo stati a fare la spesa in nott. \n",
            "Semo andati a fare una passeggiata. \n",
            "Me l'ha detto la sorella che era in casa. \n",
            "L'ha detto lui che non ci andava. \n",
            "Semo stati a casa tutta la sera. \n",
            "Semo stati a fare un giro in campagna. \n",
            "Invece de andare a scuola s'è ammalato. \n",
            "Semo stati a fare una gita con la famiglia. \n",
            "Semo andati a fare una passeggiata in nott. \n",
            "L'ha detto lui che era un pezzo. \n",
            "Semo stati a casa in tre. \n",
            "Semo stati a fare la spesa in due. \n",
            "Era stanco d'aspettare\n",
            "Le frasi delimitate da ' sono frasi del dialetto della regione abruzzo: 'sara na robba de dante... ultimamente sta in fissa...','j rutt ju cazz rete sociale italiana europea di cazzo sulla.rete dinamite di offese online fanculo','la neve l'ha sembre fatt'! . . .','so asciut' i cornetti caldi..','mettemo gli infissi ae finestre bucate','dico no, una flotta e complottista sta a rompe lu cazz con sto greenpass e la liberta violata 'nte li chiede nisciune!','e stato all'improvviso...si mangiava si beveva..nu sudore fridd fridd dietro le spalle mi sentivo morire..il rosso mi ha detto beveteci sopra ma e stato peggio..cervican...cervicale!..'.Genera 80 frasi del dialetto di abruzzo.Senza introduzione. Senza elenco puntato.Senza righe vuote. Termina ogni frase con \n",
            ".\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s'è fermato 'o camion. \n",
            "s'ha azzoppato lu sistema. \n",
            "sta n'ora ca nun me va. \n",
            "l'acqua 'a gela in inverno. \n",
            "c'era da spiegà a mio fratello. \n",
            "me pareva de finire in catastrofe. \n",
            "s'ha azzardato a dirlo. \n",
            "nun m'aspettava ca se dicesse. \n",
            "l'ho cercato in tutta a città. \n",
            "j'era dispienso, era rabbia, era disperazione. \n",
            "l'ha detto ca nun c'è speranza. \n",
            "me sembra de vederli ancora. \n",
            "sta a venì, sta a venì, nun m'ha detto c'hora. \n",
            "s'ha perso in a strada. \n",
            "me sento 'nu desiderio de fuggì. \n",
            "nun c'è più a mia nonna. \n",
            "l'ha detto ca m'aspetta. \n",
            "sta a venne la notte. \n",
            "j'ho detto ca nun m'andrei. \n",
            "l'ha fatto in un attimo. \n",
            "c'era da fà in due. \n",
            "nun m'ha dato cune risposta. \n",
            "s'ha azzardato a chiedere. \n",
            "sta a venne la primavera. \n",
            "l'ho cercato in tutta a famiglia. \n",
            "me pareva de non respirà. \n",
            "sta a venne la sera. \n",
            "l'ha detto ca nun c'è pace. \n",
            "j'era dispienso, era rabbia, era disperazione. \n",
            "l'ha detto ca m'ha tradito. \n",
            "me sento 'nu vuoto in a panza. \n",
            "sta a venne l'estate. \n",
            "nun m'ha dato cune speranza. \n",
            "l'ha fatto a scapace. \n",
            "c'era da dì a mio fratello. \n",
            "me sembra de sentì a sua voce. \n",
            "s'ha perso in a strada. \n",
            "sta a venne a primiera di novembre. \n",
            "j'ho detto ca nun m'arriamo. \n",
            "l'ha detto ca nun c'è soltitudine. \n",
            "l'ha detto ca m'ha tradito. \n",
            "me pareva de non vederli.\n",
            "Le frasi delimitate da ' sono frasi del dialetto della regione umbria: ' esce il calendario a 23 gare .. impazziti ! sono troppeeeeeehh!!! . wkd senza gran premio dio mio che noia il fine settimana senza gare fateve vede da uno bravo fateve na vita ','se magna come se sona, se sona come se magna ','folla ? annatevene a pigliallo nder cu..','a fedri' noio proponem che sarebb megl se ve l'annate a pija' n'der culo','se magna come se sona, se sona come se magna ','poraccio ,anche lui qualcosa ha da fa'....l'hanno messo li....','t'ha detto culo, i pianisti so i mejo'.Genera 80 frasi del dialetto di umbria.Senza introduzione. Senza elenco puntato.Senza righe vuote. Termina ogni frase con \n",
            ".\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S'è andà a Spole't, nudd invidiâ. \n",
            "S'è 'ncontrà 'l so frate a Terni, che ghe diseva de venì a gare a Perugia. \n",
            "A me nun m'interessa, ghe vado a gare. \n",
            "S'è piovù, nun s'è andà a gare. \n",
            "A me ghe piace, ghe dà 'na gran passione. \n",
            "L'uom t'ha detto, \"T'as da partì a l'ora\". \n",
            "Se t'as da partì a l'ora, t'as da giù a cà. \n",
            "S'è andà a gare, s'è ritornà a cà. \n",
            "T'ha dito, \"T'as un bel motor\". \n",
            "Un bel motor, ma t'ha avuto un problema. \n",
            "S'è scapà la gara, nun s'è andà a piagné. \n",
            "Ghe diseva, \"S'è andà, s'è andà\". \n",
            "S'è andà, ma l'uom t'ha detto, \"T'as tard' \". \n",
            "T'as tard', ma s'è partìo, s'è giontato. \n",
            "L'uom t'ha detto, \"T'as fatta una gara pè l'altr' \". \n",
            "Una gara pè l'altr', ma s'è ghe data tanta fatica. \n",
            "A me nun m'interessa, ghe vado a magna'. \n",
            "Se magna come se sona, se sona come se magna. \n",
            "T'ha detto, \"T'as da vè a gare\". \n",
            "T'as da vè, ma s'è dà 'na gamba a tèra. \n",
            "S'è preso, s'è portà a speta'. \n",
            "S'è andà a gare, s'è ritornà a speta'. \n",
            "A me ghe piace, ghe dà 'na gran soddisfaziun. \n",
            "L'uom t'ha detto, \"T'as da turnà indrè \". \n",
            "T'as da turnà, t'as da turnà a cà. \n",
            "S'è andà\n",
            "Le frasi delimitate da ' sono frasi del dialetto della regione trentino-alto adige: 'no, questi sono asparagi selvatici. boni anche i bruscandoi','stasera porto alla festa dell'unita di modena, i comunisti xe cussi dispera che i vota anca lu.','al mercato del pesce, la differenza tra i veneti e gli altri. altri: siamo in due persone, percio mi dia due gamberetti, tre calamari e quattro latterini per favore. veneti: semo in due, quindi fame tre porsion.','tegni bota.','no ghe n'e ','lezioni di dialetto! papa mi dai la salsiccia? questa e la luganega io!','regione d'origine: carne salda e fasoi. regione di destinazione: risotto giallo.'.Genera 80 frasi del dialetto di trentino-alto adige.Senza introduzione. Senza elenco puntato.Senza righe vuote. Termina ogni frase con \n",
            ".\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in autonome no ghe son più bei come in mont'; \n",
            "dopo la neva, i sentieri i è deserto'; \n",
            "no, el no ghe va pì'; \n",
            "i cör, i ghe custruisse un bel casin'; \n",
            "i vèsseri in calei, no ghe dispara el fresco'; \n",
            "dòmina no, om che lavora, ghe dà un dì de riposo'; \n",
            "i no ghe dà ancu el prim'; \n",
            "el fio, ghe dixe: \"pà, i vado a scuola, ghe aspetto el tuo \"si, fai cal e vieni\"\"'; \n",
            "i cumin i è stade in cantin'; \n",
            "in mont, no ghe jè on fa'; \n",
            "el vèsser, ghe diseva: \"me, ghe vado a catar un po' d'acqua, te vèn ben tìrte\"\"'; \n",
            "in autonome, no i è gnanca un cèf'; \n",
            "ghe dà ancu el segondo dì de festa'; \n",
            "in pian, i è stade mai'; \n",
            "no, i no ghe dispara el nome'; \n",
            "el fio, ghe diseva: \"pà, i vado a catar un po' de neva, te vèn con mì\"\"'; \n",
            "in val, no ghe jè on cör'; \n",
            "i vèsseri, ghe diseva: \"me, ghe vado a catar un po' de legna, te vèn con mì\"\"'; \n",
            "no, i no ghe è ancu on'; \n",
            "in autonome, i è stade mai in calei'; \n",
            "dòmina no, om che lavora, ghe dà un dì de riposo'; \n",
            "el vèsser, ghe diseva: \"me, ghe vado a catar un po' de verd, te vèn con mì\"\"'; \n",
            "no, i no ghe jè stade in calei'; \n",
            "i cumin, ghe è stade in cantin'; \n",
            "el fio, ghe diseva: \"pà, ghe vado a scuola, ghe aspetto el tuo'si, fai cal e vieni''\";\n",
            "Le frasi delimitate da ' sono frasi del dialetto della regione basilicata: 'mascherina, preservativo, guanti, gel igienizzante u cazz ca l'frec','si e perculato da solo, quello e il testo di una sua canzone. minchia, almeno le basi del fandom proprio...','insonne. esco sul balcone per una boccata d'aria. c'e traffico come se fossero le 10 di sera. ma aro' cazz jate, a chest'ora? (e non ho le traveggole: due dei miei vicini sono sul balcone come me. ma allora facciamoci una partita a ramino!)',' oggi che mangio...!?!? diciamo... nu chi je' je'... e voi ...!?!? ','si e perculato da solo, quello e il testo di una sua canzone. minchia, almeno le basi del fandom proprio...','inutile ricordare che tutti quelli che stanno partecipando a sanremo sono solo la uallera di andrea laszlo de simone','m'aggia sta accort'.Genera 80 frasi del dialetto di basilicata.Senza introduzione. Senza elenco puntato.Senza righe vuote. Termina ogni frase con \n",
            ".\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C'era l'uommo, ca stava a guardà 'a strada. \n",
            "Mangio pure ca non t'arrica nudda. \n",
            "A l'è 'a stagione, ca i ciclinde jiono 'n giardin. \n",
            "S'è fatta notte, ma a m'ha l'uocchie spie. \n",
            "L'altro jieri, a m'era sembre ca aieveva a piova. \n",
            "Tutto, pure nu caffè, m'ha fatto dormire male. \n",
            "L'ha ditto ca l'avria fatta, ma in realtà no. \n",
            "Mangio pure ca non t'arrica nudda, a me piace 'o formaggio. \n",
            "A m'ha detto: \"Ferma, no' andà\", ma a m'ho andato. \n",
            "A l'è 'a primmavera, e a l'aria m'è sofrida. \n",
            "L'è 'a sera, e a l'altro jieri a m'era a scuola. \n",
            "S'è fatta notte, e a m'ha detto: \"Non t'impavida\". \n",
            "Tutto, pure a mia sora, m'ha detto ca no, a l'ha detto a lui. \n",
            "E nun m'aspettava, a m'ha catturato 'a sorpresa. \n",
            "A l'è 'a strada, e a m'ha detto: \"Torna, torna\". \n",
            "Mangio pure ca a me piace a pizza castra. \n",
            "S'è fatta notte, e a m'ha detto: \"T'aspetta\". \n",
            "A l'è 'o mese, e a l'è 'a data, ca a m'era promess'. \n",
            "A m'ha ditto: \"Ferma, no' andà\", ma a m'ho andato a ballà. \n",
            "L'ha ditto ca l'avria fatta, ma in realtà a l'ha detto a l'uommo. \n",
            "A l'è 'a montagna, e a m'ha fatto soffrì. \n",
            "E nun m'aspettava, a m'ha detto ca aieveva\n",
            "Le frasi delimitate da ' sono frasi del dialetto della regione molise: 'io volevo andare a dormire tranquillamente mocc a sort','maronna e di ca no hahaha cm cazz e' stu fatt ahahah mi piscio','ua figl e bucchi indimen e fatt a danz ra piogg',' t'hanno sgamato, palloncino birbante . ','io volevo andare a dormire tranquillamente mocc a sort','pino stasera tu e semp c si napule','fa ancora na sfaccim e per andare in sulle mie montagne!'.Genera 80 frasi del dialetto di molise.Senza introduzione. Senza elenco puntato.Senza righe vuote. Termina ogni frase con \n",
            ".\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C'haje a dir a mme e nun a 'l mio pà. \n",
            "C'è n'omme ca t'aspetta a scurzia. \n",
            "S'è andatu a lavorà e s'è tornatu a nisciuna ora. \n",
            "Mme piace 'a sera a fa 'na passeggiata. \n",
            "T'ha detto ca vaje a Trivigno, ahahah. \n",
            "S'è fatta 'a sera bell'a, ma c'è 'na gran'umidità. \n",
            "Cchiu' bene ca mme, c'ha 'a testa ca s'aspetta. \n",
            "Mme pare ca vaje a Montagano, a passeggiare. \n",
            "S'ha perso 'o cane, ca s'era escappato. \n",
            "C'è 'nu paesano ca t'ha detto ca vaje a Campomari. \n",
            "Mme a vorebb'andà a caccia, ma c'è 'o mal di testa. \n",
            "Faccio a pensà ca vaje a San Giovanni, a nascità d'u mio frate. \n",
            "S'è fatta 'a nott'chiu' oscura, ca nun si vede nudd'. \n",
            "T'ha detto ca s'è aroppiato a lavorà, e s'è andatu a dormire. \n",
            "C'ha 'a moglie ca t'aspetta a scurzia, e nun t'ha vistu. \n",
            "S'ha dimenticato a chjàve, e s'è dàto 'o dispetto. \n",
            "Mme piace a dissi' a verità, e nun a fà finta. \n",
            "C'è 'nu paesano ca t'ha detto ca vaje a San Bartolomeo. \n",
            "S'ha preso 'o mal, e s'è andatu a veder 'o dottore. \n",
            "Faccio a sperà ca vaje a Montemitro, a visità mme sò frate. \n",
            "Mme a vorebb'andà a canta', ma c'è 'o mal di testa. \n",
            "T'ha detto ca t'ha cuntratu, a piazza, e s'è fatta a male. \n",
            "C'ha 'a casa ca\n",
            "Le frasi delimitate da ' sono frasi del dialetto della regione valle d'aosta: 'margherita di savoia je t'aime , ta devise : sempre avanti','max col suo cappotto gli fa na pippa','ma vai a nasconderti...che di te non ce n'e bisogno, vivi la tua vita e non rompere i maroni agli altri.',' crosetto...non ha ancora imparato quando a le mie ste ciutu pr nen fe la figura dl gadan ? cai prova....magari a ries! ','si, sapevo del suo cote piacione, ma la trasformazione del cognome in sdrucciola non mi era mai venuta in mente! solo voi toscani','come 'na barca int'al bosc. scusa il maccheronico.',' un americano fatto comme il faut ......la faccia da gioppino.....e auguri x un natale unico, memorabile.....ma sempre un natale e !!!!! vi lovvo '.Genera 80 frasi del dialetto di valle d'aosta.Senza introduzione. Senza elenco puntato.Senza righe vuote. Termina ogni frase con \n",
            ".\n",
            "\n",
            "\n",
            "Cà mò a ven a fè la valoriza da na giornata d'invern. \n",
            "Töi che t'é andà a caccia, l'ha pasàa la coda al can. \n",
            "La pèsse, la l'ha piantà in giardin, e a l'é cresciüda comme un alberedon. \n",
            "I valladese, i l'ha fatta la fèsta, quand a l'é uscìü la notizia. \n",
            "Un pô, un pô, a l'é andà a studeggià a Torin, ma a l'ha troväa trop lontan. \n",
            "E a l'é mòrt a Giorgi, a fradeło, e a l'é un pò' dispiönt a sò mère. \n",
            "A l'é andà a corte a la sò, e a l'é staciaa un pò', e a l'é partìü a dìto a l'àtra. \n",
            "L'uom, l'uom, a l'é staciaa in piazza, e a l'ha comencià a cantà la sò cançon. \n",
            "A l'é andà a fè la spesa, e a l'é dàita a sò mari a dà a mangiä. \n",
            "La neve, la neve, a l'é cadüa, e a l'é staciaa in pila, e a l'é dàita a fè la slitta. \n",
            "Quand a l'é andà a scola, a l'ha pasàa la partì a gieu, e a l'é restàa in class. \n",
            "A l'é andà a caccia, e a l'é tornà a cà, e a l'é fàita a stufada. \n",
            "I doi, i l'era andà a spasseggià, e a l'é staciaa in piazzetta, e a l'é dàita a fè la foto. \n",
            "A l'é mòrt a sò nonno, a l'ha dàita un pò' de lutto, e a l'é andà a messa. \n",
            "A l'é andà a fè la rixe, e a l'é tornà a cà, e a l'é dàita a mangi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_new = pd.DataFrame(add)\n",
        "df_combined = pd.concat([df_prov, df_new], ignore_index=True)\n",
        "df_combined['region'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYVXVvKVqfhF",
        "outputId": "3b943d20-e8fe-4398-9cb6-4b43a20bb81a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "region\n",
              "abruzzo                  80\n",
              "sicilia                  65\n",
              "calabria                 62\n",
              "marche                   59\n",
              "lombardia                57\n",
              "piemonte                 54\n",
              "umbria                   54\n",
              "basilicata               53\n",
              "friuli-venezia giulia    52\n",
              "trentino-alto adige      50\n",
              "sardegna                 46\n",
              "veneto                   44\n",
              "emilia romagna           43\n",
              "molise                   42\n",
              "toscana                  41\n",
              "puglia                   40\n",
              "valle d'aosta            31\n",
              "liguria                  29\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_combined.to_csv('NLP_Dataset_OS.csv',index=False)"
      ],
      "metadata": {
        "id": "fbxT3I8mtwdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_combined.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJViMOKLIhwy",
        "outputId": "84361bbc-dde9-4eca-c211-dcfdc0201c98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(902, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_OS = pd.read_csv(\"Dataset_Quarto.csv\")\n",
        "df_combined = pd.concat([df_OS,df_combined], ignore_index=True)\n",
        "df_combined.to_csv('Dataset_Quarto.csv',index=False)\n",
        "df_combined['region'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8IcbjBcA-zY",
        "outputId": "dd7cc259-82fc-4208-bea7-5a47ecd666ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "region\n",
              "lazio                    5614\n",
              "campania                 3046\n",
              "veneto                   1979\n",
              "sicilia                  1848\n",
              "lombardia                1802\n",
              "toscana                  1649\n",
              "sardegna                 1535\n",
              "calabria                 1508\n",
              "puglia                   1429\n",
              "piemonte                 1413\n",
              "friuli-venezia giulia    1387\n",
              "emilia romagna           1379\n",
              "marche                   1321\n",
              "liguria                  1319\n",
              "basilicata               1304\n",
              "abruzzo                  1300\n",
              "umbria                   1246\n",
              "trentino-alto adige      1226\n",
              "molise                   1226\n",
              "valle d'aosta             948\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_combined.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuyZ_p-sB_Rk",
        "outputId": "00f3d6a1-a79e-4abd-bf88-20113dc6568b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(33577, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After several iterations we managed to make the dataset bigger with the addition of 19,754 examples going also to increase the examples of the Minonitary classes."
      ],
      "metadata": {
        "id": "Tvk7okxPpQa-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK: Classification of sentences by region\n",
        "The main task that you want to satisfy in this project is the classification of dialect phrases by region.\n",
        "To do this, an SVM classifier from SKlearn is implemented."
      ],
      "metadata": {
        "id": "naGW3AIKbsdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from sklearn.base import TransformerMixin\n",
        "from statistics import mean, stdev\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import StratifiedKFold\n"
      ],
      "metadata": {
        "id": "Q475JTMxiWEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Dataset_Quarto.csv\")\n",
        "df = df.drop(['Unnamed: 0'],axis = 1)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Of65sl74k82H",
        "outputId": "8030bc9a-a48a-49f4-8460-38491c55a72b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text         region\n",
              "0       il chiosco bar e dove si e co i lettini,appen...          lazio\n",
              "1       so' monticiano, so', sangue de zio! so' nato ...          lazio\n",
              "2       veneziani, gran signori; padovani, gran dotor...         veneto\n",
              "3      poi se bu avanzanu zeppule passati de casa ca ...       calabria\n",
              "4      come disse n'amica mia anni fa, alla seconda f...          lazio\n",
              "...                                                  ...            ...\n",
              "34474  Quand a l'é andà a scola, a l'ha pasàa la part...  valle d'aosta\n",
              "34475  A l'é andà a caccia, e a l'é tornà a cà, e a l...  valle d'aosta\n",
              "34476  I doi, i l'era andà a spasseggià, e a l'é stac...  valle d'aosta\n",
              "34477  A l'é mòrt a sò nonno, a l'ha dàita un pò' de ...  valle d'aosta\n",
              "34478  A l'é andà a fè la rixe, e a l'é tornà a cà, e...  valle d'aosta\n",
              "\n",
              "[34479 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ca17e850-2b20-4714-8e27-54726498c711\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>region</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>il chiosco bar e dove si e co i lettini,appen...</td>\n",
              "      <td>lazio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>so' monticiano, so', sangue de zio! so' nato ...</td>\n",
              "      <td>lazio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>veneziani, gran signori; padovani, gran dotor...</td>\n",
              "      <td>veneto</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>poi se bu avanzanu zeppule passati de casa ca ...</td>\n",
              "      <td>calabria</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>come disse n'amica mia anni fa, alla seconda f...</td>\n",
              "      <td>lazio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34474</th>\n",
              "      <td>Quand a l'é andà a scola, a l'ha pasàa la part...</td>\n",
              "      <td>valle d'aosta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34475</th>\n",
              "      <td>A l'é andà a caccia, e a l'é tornà a cà, e a l...</td>\n",
              "      <td>valle d'aosta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34476</th>\n",
              "      <td>I doi, i l'era andà a spasseggià, e a l'é stac...</td>\n",
              "      <td>valle d'aosta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34477</th>\n",
              "      <td>A l'é mòrt a sò nonno, a l'ha dàita un pò' de ...</td>\n",
              "      <td>valle d'aosta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34478</th>\n",
              "      <td>A l'é andà a fè la rixe, e a l'é tornà a cà, e...</td>\n",
              "      <td>valle d'aosta</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34479 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca17e850-2b20-4714-8e27-54726498c711')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ca17e850-2b20-4714-8e27-54726498c711 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ca17e850-2b20-4714-8e27-54726498c711');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-133d70cf-f2aa-4848-90f1-6f04f1ce56a1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-133d70cf-f2aa-4848-90f1-6f04f1ce56a1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-133d70cf-f2aa-4848-90f1-6f04f1ce56a1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_a50427bd-c8c8-47dc-8daa-9346b06e5cae\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a50427bd-c8c8-47dc-8daa-9346b06e5cae button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 34479,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 33627,\n        \"samples\": [\n          \"A sciorta ca nun \\u00e8 'n'ommo santo. \",\n          \"S'ha da cunfes' se chella nova non m'aggezza. \",\n          \"La strada era tutta bagnata, tutta, tutta, come se avesse mangiato un oceano d'acqua. \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"region\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"lazio\",\n          \"marche\",\n          \"emilia romagna\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#decoding text from latin-1 to utf-8\n",
        "df['text'] = df['text'].apply(lambda x: x.decode('latin-1') if isinstance(x, bytes) else x)\n",
        "#replacing Nan values with empty strings\n",
        "df['text'].fillna('', inplace=True)"
      ],
      "metadata": {
        "id": "uX0WkBpmmxgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['text'].to_numpy()\n",
        "y = df['region'].to_numpy()"
      ],
      "metadata": {
        "id": "jnkQQBmBm5sA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textclassifier = ImbPipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('mnb', SVC())\n",
        "])"
      ],
      "metadata": {
        "id": "Gj0KT7oVnVgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "n_splits = 20\n",
        "\n",
        "fmacro = 0\n",
        "fmicro = 0\n",
        "facc = 0\n",
        "frecall = 0\n",
        "fprecision = 0\n",
        "y_gt= []\n",
        "y_pred = []\n",
        "\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
        "\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "  x_train_fold, x_test_fold = X[train_index], X[test_index]\n",
        "  y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
        "  textclassifier.fit(x_train_fold, y_train_fold)\n",
        "  pred = textclassifier.predict(x_test_fold)\n",
        "\n",
        "  y_gt.extend(y_test_fold)\n",
        "  y_pred.extend(pred)\n",
        "\n",
        "  # Valutation metrics\n",
        "  fmacro += metrics.f1_score(y_test_fold, pred, average='macro')\n",
        "  fmicro += metrics.f1_score(y_test_fold, pred, average='micro')\n",
        "  facc += metrics.accuracy_score(y_test_fold, pred)\n",
        "  fprecision += metrics.precision_score(y_test_fold, pred, average='macro')\n",
        "  frecall += metrics.recall_score(y_test_fold, pred, average='macro')\n",
        "\n",
        "print(\"\\n========================================================================================================================================\")\n",
        "print(\"Accuracy:\", facc/n_splits)\n",
        "print(\"P={0}, R={1}, F1 Macro={2}, F1 Micro={2}\".format(fprecision/n_splits, frecall/n_splits, fmacro/n_splits, fmicro/n_splits))\n",
        "print(\"========================================================================================================================================\")\n",
        "print(metrics.classification_report(y_gt, y_pred, digits=2))"
      ],
      "metadata": {
        "id": "IEt0xCcczEpC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f85e51df-eb5c-4d75-baca-66000343d664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================================================================================================================\n",
            "Accuracy: 0.7005137770278733\n",
            "P=0.7101501776285007, R=0.6471214558008442, F1 Macro=0.671757058855882, F1 Micro=0.671757058855882\n",
            "========================================================================================================================================\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "              abruzzo       0.64      0.51      0.57      1300\n",
            "           basilicata       0.68      0.58      0.63      1304\n",
            "             calabria       0.70      0.57      0.63      1508\n",
            "             campania       0.78      0.85      0.81      3046\n",
            "       emilia romagna       0.61      0.50      0.55      1379\n",
            "friuli-venezia giulia       0.72      0.66      0.69      1387\n",
            "                lazio       0.63      0.96      0.76      5614\n",
            "              liguria       0.77      0.61      0.68      1319\n",
            "            lombardia       0.70      0.60      0.64      1802\n",
            "               marche       0.66      0.51      0.57      1321\n",
            "               molise       0.66      0.57      0.61      1226\n",
            "             piemonte       0.68      0.61      0.64      1413\n",
            "               puglia       0.69      0.60      0.64      1429\n",
            "             sardegna       0.91      0.85      0.88      1535\n",
            "              sicilia       0.76      0.79      0.77      1848\n",
            "              toscana       0.71      0.65      0.68      1649\n",
            "  trentino-alto adige       0.71      0.60      0.65      1226\n",
            "               umbria       0.65      0.51      0.57      1246\n",
            "        valle d'aosta       0.77      0.65      0.71       948\n",
            "               veneto       0.73      0.78      0.75      1979\n",
            "\n",
            "             accuracy                           0.70     34479\n",
            "            macro avg       0.71      0.65      0.67     34479\n",
            "         weighted avg       0.70      0.70      0.69     34479\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "textclassifier.predict([\"c'ama sci sciamanin\"])"
      ],
      "metadata": {
        "id": "HHMgx7XbzerW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ec0a2c5-d266-48b8-c942-b1ef0ec69bc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['puglia'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the results obtained. We can see that:\n",
        "- Accuracy: The model achieved an overall accuracy of 70%, indicating that 70% of the phrases were correctly classified.\n",
        "- Recall medium: The average recall is 65%, indicating that the model is moderately effective in capturing all dialect phrases for each region.\n",
        "- F1 average score: The F1 average score is 67%, which represents a good balance between accuracy and recall.\n",
        "\n",
        "In detail we have that:\n",
        "- The dialect of Sardinia is classified more precisely.\n",
        "- The dialect of the Emilia-Romagna region is classified with less precision."
      ],
      "metadata": {
        "id": "jzqbUUoOrO-4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# EXTRA TASK: Translation of dialect phrases\n",
        "\n",
        "Another experiment that has been conducted within this project is to test Lamantino’s performance in translating dialect phrases.\n",
        "To conduct this experiment was first loaded the model and defined its role within this task.\n"
      ],
      "metadata": {
        "id": "xBu_6wPobznC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQnL8k10ytn1",
        "outputId": "d61179f1-3573-40e7-99ee-16203abd6894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sys = \"Sei un assistente digitale AI per la lingua dialettale italiana di nome LLaMAntino-3 ANITA.\" \\\n",
        "    \"(Advanced Natural-based interaction for the ITAlian language).\" \\\n",
        "    \"Traduci in italiano le espressioni dialettali che si trovano all'interno del testo fornito dall'utente,ma senza cambiare il significato e la sintassi del testo. \"\n",
        "\n",
        "import transformers\n",
        "pipe = transformers.pipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    return_full_text=False, # langchain expects the full text\n",
        "    task='text-generation',\n",
        "    max_new_tokens=512, # max number of tokens to generate in the output\n",
        "    temperature=0.5,  #temperature for more or less creative answers\n",
        "    do_sample=True,\n",
        "    top_p=0.9\n",
        ")\n"
      ],
      "metadata": {
        "id": "fCMKC_9xtRvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df= pd.read_csv(\"Dataset_Quarto.csv\")\n",
        "add = {\"trad\": []}\n",
        "df = df.drop(['Unnamed: 0'],axis = 1)\n",
        "apulia = df[df['region']=='puglia']"
      ],
      "metadata": {
        "id": "hcM6u2FwDR4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to evaluate the quality of the translation, the task requires you to have a dataset containing manual translations, made by local people, of the sentences. So you can compare them with machine translations.\n",
        "For time reasons, 100 sentences belonging to the Apulian dialect have been manually and automatically translated."
      ],
      "metadata": {
        "id": "8PQpshbSt4--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "apulia = apulia[:100]\n",
        "apulia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "-jfzm1G1GbRD",
        "outputId": "70f4b32e-1e8d-45f1-8e9a-7fc349aeb7e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  region\n",
              "34     una grandissima artista barese ci lascia. add...  puglia\n",
              "52     raffaele, mi sembra che sto'parlando con mio ...  puglia\n",
              "59                                bbeddhi comu lu sule   puglia\n",
              "122      versione barese. la nonn gastema ! scritto da   puglia\n",
              "325    la reazione di mio padre, da incorniciare, co...  puglia\n",
              "...                                                 ...     ...\n",
              "5490    te mpauri de mie tie ahahhah sine sine la porto  puglia\n",
              "5530         anche perche no je manc sicur ca riman idd  puglia\n",
              "5603       lu sule c'e. lu mare c'e... lu jentu...no...  puglia\n",
              "5606  aggiu' capito michele stai passando, con: cara...  puglia\n",
              "5659  stefano reali tutt tu tutt tu e fasc sti ralle...  puglia\n",
              "\n",
              "[100 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6105f3c6-33a2-4462-b99a-3be9b9e6e0c3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>region</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>una grandissima artista barese ci lascia. add...</td>\n",
              "      <td>puglia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>raffaele, mi sembra che sto'parlando con mio ...</td>\n",
              "      <td>puglia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>bbeddhi comu lu sule</td>\n",
              "      <td>puglia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>versione barese. la nonn gastema ! scritto da</td>\n",
              "      <td>puglia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>325</th>\n",
              "      <td>la reazione di mio padre, da incorniciare, co...</td>\n",
              "      <td>puglia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5490</th>\n",
              "      <td>te mpauri de mie tie ahahhah sine sine la porto</td>\n",
              "      <td>puglia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5530</th>\n",
              "      <td>anche perche no je manc sicur ca riman idd</td>\n",
              "      <td>puglia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5603</th>\n",
              "      <td>lu sule c'e. lu mare c'e... lu jentu...no...</td>\n",
              "      <td>puglia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5606</th>\n",
              "      <td>aggiu' capito michele stai passando, con: cara...</td>\n",
              "      <td>puglia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5659</th>\n",
              "      <td>stefano reali tutt tu tutt tu e fasc sti ralle...</td>\n",
              "      <td>puglia</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6105f3c6-33a2-4462-b99a-3be9b9e6e0c3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6105f3c6-33a2-4462-b99a-3be9b9e6e0c3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6105f3c6-33a2-4462-b99a-3be9b9e6e0c3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-527dec40-429c-40b1-848d-829b0369a4dc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-527dec40-429c-40b1-848d-829b0369a4dc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-527dec40-429c-40b1-848d-829b0369a4dc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_36e1a7d4-5921-4187-9baa-dc0c79d2dd30\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('apulia')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_36e1a7d4-5921-4187-9baa-dc0c79d2dd30 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('apulia');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "apulia",
              "summary": "{\n  \"name\": \"apulia\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"lu sole, lu mare, lu jentu. \",\n          \"lu sole, lu mare, lu candri.... \",\n          \"arret! considerati gia con l'anello al dito\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"region\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"puglia\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in tqdm(apulia.to_numpy()):\n",
        "  prompt = f\"\"\"Testo: \"{sentence[0]}\".\n",
        "  Il testo è scritto nel dialetto della regione italiana {sentence[1]},\n",
        "  traducilo in lingua italiana senza cambiare nè la sua semantica nè la sua sintassi.\n",
        "  Termina la traduzione con un \"\\n\".\n",
        "  Non devono essere date in output altre informazioni oltre la traduzione.\n",
        "  Non aggiungere parentesi o altri commenti. Non aggiungere parole inglesi o italiane che non siano già presenti nel testo.\n",
        "  Lascia invariati i termini che sono già all'interno del testo in lingua italiana o inglese.\n",
        "  Rispondi solo con la traduzione letterale.\n",
        "  Non saltare nessuna parte del testo. Neanche quelle che originariamente sono tra perentesi nel testo.\n",
        "  \"\"\"\n",
        "\n",
        "  messages = [\n",
        "      {\"role\": \"system\", \"content\": sys},\n",
        "      {\"role\": \"user\", \"content\": prompt}\n",
        "  ]\n",
        "\n",
        "  sequences = pipe(messages)\n",
        "\n",
        "  for seq in sequences:\n",
        "      generated_text = seq['generated_text']\n",
        "      print(f\"{seq['generated_text']}\")\n",
        "\n",
        "      # Split phrases into separate rows (if necessary)\n",
        "      if \"\\n\" in generated_text:\n",
        "          phrases = generated_text.split(\"\\n\")\n",
        "          add[\"trad\"].extend(phrases)\n",
        "      else:\n",
        "          add[\"trad\"].append(generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1pCOhqmtbA7",
        "outputId": "bb43b1bf-da89-41d8-f28b-b949c2e8f025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/100 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "  1%|          | 1/100 [00:05<08:50,  5.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Una grande artista barese ci lascia. Addio a Mariolina de Fano. Eccola qui che interpreta la vecchia e la morte. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 2/100 [00:11<09:28,  5.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raffaele, mi sembra di dire cose che dicono mio figlio. Quindi basta dire: il mondo è il mondo sarà'. Mi dà fastidio, di chi non vuole collaborare con l'Italia. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 3/100 [00:14<07:02,  4.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Bene come il sole\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 4/100 [00:17<06:24,  4.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Versione pugliese. la nonna è geniale! scritto da \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 5/100 [00:22<07:05,  4.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Guarda un po' che adesso dovresti soffocare! pure sulla coscienza ti dovrebbero tenere in paura Ermete e Fabrizio' \".\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 6/100 [00:25<06:00,  3.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "una cattiva faccia'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 7/100 [00:30<06:24,  4.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accendo la tv, nonno resta a guardare la tv, mi guarda: che ci sta aspettando, si è capito subito.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 8/100 [00:33<05:48,  3.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None e non è con te, è con il capo'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 9/100 [00:38<06:11,  4.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Un mese senza di te e già passato un mese da quando te ne sei andato da qui, ci manchi tanto, giù arriverci, addio.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 10/100 [00:42<06:26,  4.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sei molto bella, vieni a trovarmi. qui c'è il vento, il sole, il mare. baci, amore mio.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 11/100 [00:45<05:30,  3.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "e quando passa \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 12/100 [00:48<05:18,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "slow motion che non ha nulla a che fare, ma che sempre piace in fine.. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 13/100 [00:51<04:47,  3.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ma non è giusto poco' \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 14/100 [00:57<05:51,  4.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Secondo me la cosa è stata smontata dalla falsa notizia e questo è tutto... ecco i silenzi e tutte quelle storie fatte di sussurri etc etc... stiamo senza progresso!!! \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 15/100 [01:00<05:25,  3.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Mum, mum, mum, forse un neurone si è illuminato\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 16/100 [01:03<04:56,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " donne. fuori di testa. le migliori.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 17/100 [01:07<05:05,  3.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Buongiorno bella rossa!!!! da quelle parti rosso si dice cosi, rossina.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 18/100 [01:10<04:44,  3.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Hahahahahahha la risata del gatto\".\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 19/100 [01:13<04:27,  3.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Salento... il sole... il mare... il vento.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 20/100 [01:15<04:12,  3.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Il cielo, il mare, il vento \".\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 21/100 [01:21<05:12,  3.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Sia detto pure dopo. non prima e durante, mi pare una battuta di cattivo gusto però stanno soffocati da ansie, è necessario un gol di conforto e risolleve\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 22/100 [01:25<05:06,  3.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Ci ridefinisce in giro il cappello sugli alti per lui sa sopra le cose del mondo\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 23/100 [01:28<04:43,  3.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sai cosa vuole dire esser tradito, accidì!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 24/100 [01:37<06:31,  5.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chi si fa crescere i capelli ora per moda e per TikTok, un mullet a quel tempo non lo portava nessuno, dov'era quando mi davano del renegato e quando i giullari uscivano con la loro lite con il barbiere, bro, la tua ragazza mi pettina, ma che non ne capisci tu, since 2003 \".\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 25/100 [01:40<05:43,  4.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sabino: lo va a pigliare in un'altra birra.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 26/100 [01:45<05:45,  4.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ieri Google mi aveva assicurato che oggi ci sarebbero stati in meno, sta me pigliere pe il fatto?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 27/100 [01:51<06:06,  5.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ripropongo: la testa non serve a separare le orecchie (... cit.) (la testa non serve a sostenere le impugnature degli occhiali. (sembrano pochi)) \".\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 28/100 [01:53<05:09,  4.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Il mare il sole il vento \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 29/100 [01:59<05:24,  4.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"a Leccë si dice ci cappa ci cappa, a Roma si dice dico dico, in Calabria a ci pigghia pigghia\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 30/100 [02:05<05:59,  5.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Un'amica mi ha chiamato per chiedermi se \"stu bebbe\" fosse un termine pugliese o salentino, non potevo non condividerle questa perlita di insensato - non senso ci vu'\".\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 31/100 [02:08<05:05,  4.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non torni, non ritorna...\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 32/100 [02:16<06:16,  5.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "... comunque: e inutile la morte del film, non c'è nulla di fatto! come urla dalla galleria, Gianni Ciardo al cinema Royal di Bari, durante il secondo tempo del film, dopo l'ennesimo fallimento di capire la piovra enorme. ricordi di una Bari che non c'è più. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 33/100 [02:19<05:32,  4.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Figlio mio disse mio padre a mio padre. Il mondo è stretto di sagare (il difficile).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 34/100 [02:25<05:42,  5.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Un uomo distrutto siede su una panchina di Bari. E comunque meglio distrutto e felice come me come noi che distrutto e muto come li lazi in Roma'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 35/100 [02:28<04:55,  4.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"bravissimo fiore, con tutto il cuore\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 36/100 [02:31<04:19,  4.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Un tipo di persona, si direbbe da quelle parti. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 37/100 [02:39<05:22,  5.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La penso come te, Enrico, ce ne fossero persone come te, poi se abortisci te si sgrava la frasca, e mio padre diceva sempre che la frasca di una donna è come il marmo, va tenuto pulito e conservato in purezza.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 38/100 [02:42<04:51,  4.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Per te vada bene, ma a me serve una ragazza con una bella perché... viva la fuga.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 39/100 [02:45<04:06,  4.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Qui gli ha fatto gratuitamente \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 40/100 [02:56<06:15,  6.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ragazzi, questa donna, come si dice a Bari, è storta! leggete bene e dimenticate le menzogne che vi raccontano i negazionisti e i venduti ai sovranisti.\n",
            " la spagna, la francia, la grecia e la germania sono di nuovo nei guai, il regno unito non è mai uscito dai guai.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 41/100 [03:00<05:17,  5.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "e diciamolo pure!!! è stato detto pure in tutta la città!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 42/100 [03:08<06:09,  6.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vado distratto abbandonato là dove sono le occhiate nascoste nel cappello, mano in mezzo al gelo e maschera inaspettata, vado cercando e stelle che sono secche e mi parla di te, io le domando se aspetta per me e mi risponde: se lo vuole sa che non c'e nessuno \".\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 43/100 [03:11<05:02,  5.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+ 18 anni passati all'amore mio\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 44/100 [03:16<04:48,  5.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Il cielo, il mare, il vento. Spero che si fermi, non vorrei che l'estate sia così' \".\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 45/100 [03:21<04:34,  4.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "uno e dio l'altro è uno che non crede in ciò che si crede in terra lo so e sarei un ateo ma fate una risata \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 46/100 [03:24<04:08,  4.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ok l'errore del portiere, ma in gabbia stanno quei sotti di casa\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 47/100 [03:28<03:43,  4.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non ha senso andare da mamma di Mark Zuckerberg\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 48/100 [03:33<03:50,  4.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Che sciocchezza di notizia e? ma siete in credibili? che relazione c'è col vaccino? o relazione ce fa un di mammo di zero? \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 49/100 [03:35<03:14,  3.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"E un gran bene!\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 50/100 [03:46<04:51,  5.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ricordi i pranzi estivi di mia nonna: orecchiette fatte in casa con ragù! Scarso, duecento cinquanta grammi! Carne nel sugo di tutte le tipologie! Cotolette con patate fritte e insalata! Formaggi vari, che ti avrebbe mangiato! Macedonia e baba! Questo in mezzo alla settimana! La domenica non ve lo racconto.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 51/100 [03:55<05:38,  6.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Come mi ha detto un collega dopo una partita a Melito con la squadra dell'ordine, quando io gli ho detto: \"nel manuale dell'ingegnere trovi facilmente un piccolo telaio, un telaietto risolto! - te lo dico? sta' tranquillo, ché sta a sacciu!\"\n",
            "\" (ancora rido)\".\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 52/100 [04:01<05:13,  6.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "anche qui si dice: il purpiero si cuoce nell'acqua sua\n",
            "btw dato un'occhiata alla Le Creuset evolution che penso sia la tua\n",
            "consiglio la 26 o 28 cm? \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 53/100 [04:09<05:38,  7.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dormi bene dormi cara il Signore ti benedica dormi figlia non ti spaventare ca' niente chiuso ti può tocare dimentica gli ultimi urti troppo chini di dolori chiudi gli occhi tu bene stringimi la mano all'angolo buon viaggio piccola e dolce Elena.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 54/100 [04:12<04:31,  5.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Il sole, il mare, i lampioni. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 55/100 [04:15<03:45,  5.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Salento: il mare, il sole e il vento \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 56/100 [04:19<03:27,  4.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Oh signore, ti è passato sopra un tiro? e fattela una risata\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 57/100 [04:22<02:55,  4.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Il dialetto ti francostra \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 58/100 [04:24<02:33,  3.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Mammaaaaa, mi vado male...\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 59/100 [04:27<02:16,  3.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Te voglio bene assai\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 60/100 [04:31<02:23,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Avevo domani giù vedo alla festa di Sandanò... ah, no...\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 61/100 [04:34<02:14,  3.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Il cielo, il mare e il sfruttamento. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 62/100 [04:37<02:01,  3.21s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Mama, c'è brutto\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 63/100 [04:41<02:07,  3.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "il primo ministro inglese, da negazionista a rigorista, ovvero quando uno si sbatte a fondo.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 64/100 [04:45<02:07,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Io capisco che la mattina vi trovate in difficoltà, no di là?\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 65/100 [04:52<02:39,  4.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oggi è un sabato inizio di vacanza domani non si va a scuola oggi e sabato se non chiami ho un nervoso in gola oggi e sabato e forse un giorno speciale oggi e sabato, meno male ogni ragazzo è bello a mamma sua.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 66/100 [04:57<02:42,  4.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Si non è uscito bene da lì, e in effetti sei uscito con un fallimento da una masturbazione andata male. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 67/100 [05:00<02:18,  4.21s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ciò che è fatto a me è stato fatto.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 68/100 [05:07<02:41,  5.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Arco, colonna e donna carica quanta uei ca non ci sponda!! cit. proverbio salentino del fabbricatore \".\n",
            "Traduzione: \"Arco, colonna e donna carica quanta ne può non ce ne sta!! cit. proverbio salentino del costruttore \".\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 69/100 [05:14<02:59,  5.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Posto inizio (il), 28.8.2020 dopo tre anni in cui non ci siamo, non per colpa mia, eccomi qui! ti trovo in ottima forma, dolce, come sempre e domani all'alba correrò con te in coda di ligno, promesso'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 70/100 [05:22<03:07,  6.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "e hm... ci farebbe cazzo se fosse cosi: ma chiamando ci farebbe cazzo che tena questo! (guarda che faccia di cattivo ha questo) nel caso di Gauss e per dire che carino. ci sono altre accezioni negative. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 71/100 [05:25<02:34,  5.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Stop! considera te già col anello alla dura fessa\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 72/100 [05:31<02:33,  5.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non si giocava con cose serie come i cromosomi, non è divertente e non lo sono neanche i laziali a questo proposito. su queste cose non c'è da scherzare'. per favore.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 73/100 [05:35<02:21,  5.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "invece dei calabresi o dei terroni gobbi e giusto?vero? allora vi dico si no\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 74/100 [05:42<02:30,  5.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Tu Simone Pillon si adivèr tromo! confondere il suicidio, causato da stato depressivo, assolutamente frutto di pensiero malato, con la scelta ragionata di interrompere le sofferenze di malati terminali. vergogna.\n",
            "\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 75/100 [05:49<02:28,  5.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "e il sole, il mare e il vento sorride grande e il Salento, la nostra terra sorriso grande e fuori c'è il sole, oggi non si muore d'amore\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 76/100 [05:58<02:43,  6.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non ce ne sarebbe più neanche se dovesse esserci un lockdown mondiale per cinque anni, i ghiacci si scioglierebbero lo stesso. Il resto tornerebbe alla vita invece. Io però cinque anni mi fermerei, intendo tutto ciò che è meccanico ed industriale e tu? no? E allora di che stiamo a parlare!? \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 77/100 [06:05<02:39,  6.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non fare il furbetto! rispettando leggi e norme di legge, da fonti normative in vigore! e lo sai bene, lascia perdere! piangendo piangendo vi hanno regalato lo scudetto della Serie A, bravo bravo.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 78/100 [06:07<02:04,  5.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chi è costui e questo? \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 79/100 [06:10<01:40,  4.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Il cielo il sole il mare il vento.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 80/100 [06:16<01:39,  4.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"In una minima misura l'ho visto ieri sera sembra in un ricongiungimento del cast del film in origine, da guardare senza grandi aspettative\".\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 81/100 [06:23<01:47,  5.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Breve storia: mia mamma ha iniziato a appassionarsi al calcio 7 anni fa, ho detto tutto.\n",
            "  pazza di Paulinato, ogni volta che lo inquadravano lei: \"ma che bel piccolo e lei non parla mai in italiano, giuro\" \".\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 82/100 [06:28<01:38,  5.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Anni fa facevano lo stesso con Dybala al Camp Nou, poi vedi adesso e in un attimo. Ci vuole equilibrio'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 83/100 [06:32<01:24,  4.98s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "per passare ci vuole la maschera antigas perche non si passa in mezz'aere\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 84/100 [06:35<01:09,  4.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Il sole, il mare, la gente. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 85/100 [06:38<01:00,  4.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Ehi signore mio, butta via il sangue!\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 86/100 [06:45<01:08,  4.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Il carnevale si trova qui! Via Roma, il cibo che dà identità e appartenenza... tornerà il consueto! La mostra a cielo aperto restituisce un'immagine di un carnevale popolare, inclusivo e partecipato.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 87/100 [06:51<01:07,  5.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Questo è vero! Mauro è un giocatore storico del calcio! Primo coro di sfida tra tifosi era chi non segue e nuovo baresotto qui a Lecce canta ogni partita \".\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 88/100 [06:53<00:52,  4.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polli morti sul letto.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 89/100 [06:59<00:52,  4.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Mumma the words out, you don't understand a thing. You still haven't got it and you're trying in vain to deceive Jessica. He got it and the first alarms are ringing from the closets.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 90/100 [07:03<00:46,  4.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ho visto le ultime storie di Petalow e la voce di Gino m'ha fatta scuotere\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 91/100 [07:09<00:44,  4.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sono irascibili, accaniti, arrabbiati e testa di muro come muli! li chiamano testa dura... conto uno che dice il vero! un mulo da carico\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 92/100 [07:14<00:39,  4.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "&E amici per le strade di Napoli a mangiare pizza fritta e un po' e sederci e mangiar friarielli e poi chiudere con una montagna di baba'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 93/100 [07:17<00:31,  4.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Oh, quanto poco! quanto è la mia mano, piccola!\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 94/100 [07:22<00:27,  4.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "e noi stiamo ballando, anzi, stiamo facendo la salsa. buonbye dal gruppo (dei) cuori (cuppone) \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 95/100 [07:28<00:24,  4.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ma cosa devono dire, questi personaggi, quando vanno in tv sono capaci di dire qualsiasi cosa per confermare le loro teorie per le partite di calcio, sto sciocco di merda'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 96/100 [07:31<00:17,  4.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ti pauro di me, non la porto.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 97/100 [07:34<00:12,  4.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "anche perché no, io non manco di sicuro che rimanga lui.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 98/100 [07:37<00:07,  3.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Il sole c'è, il mare c'è... il vento no...\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 99/100 [07:45<00:04,  4.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Io ho capito che a Michele stanno preparando, con: caramelle, pastiglie, succhi di frutta, giuochi, palloncini, e vino, il miglior vino rosso, per incominciare la festa.\".\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [07:49<00:00,  4.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Stai realista, tutto tu, tutto tu, e fascia stai lentamente? Dov'è sta bella?\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "add[\"trad\"]"
      ],
      "metadata": {
        "id": "0PnD9I1fitr4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "f6b640ae-9b2b-4e00-ba13-2ace1b38cff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\"One great artist from Bari leaves. Farewell to Mariolina de Fano. here she is, in a performance of old age and death, in a song\".',\n",
              " '\"One great artist from Bari leaves us. Farewell to Mariolina De Fano. here she is, in a performance of old and death\\'s way \"',\n",
              " '',\n",
              " '(Note: I tried to maintain the original meaning and the poetic tone of the text, while translating it from the Pugliese dialect to Italian. The translation might not be a direct word-for-word translation, but an interpretation of the original text in the Italian language.)',\n",
              " 'Una grande artista barese ci lascia. Addio a Mariolina De Fano. Eccola qui che interpreta la morte e la vecchiaia.',\n",
              " \"Raffaele, mi sembra di parlare con il mio figlio. Quindi basta dire: il mondo è il mondo sarà'. Mi dà fastidio, di chi non vuole collaborare con l'Italia.\",\n",
              " '\"Bene come il sole\"',\n",
              " 'Versione italiana. La nonna gasta il tempo! scritto da \"',\n",
              " \"Guarda un po' che adesso dovresti soffocare! pure sulla coscienza ti dovrebbero tenere in stato di reazione Ermete e Fabrizio.\",\n",
              " 'Una cattiva faccia\"',\n",
              " 'Accendo la tv, il nonno guarda la tv, mi guarda: che ci sta aspettando resto? ha già capito tutto. \"',\n",
              " 'None e non è per te capo.',\n",
              " 'Un mese senza di te e già passato un mese da quando te ne sei andato da qui, ci manca tanto, arrivederci, addio.',\n",
              " \"Sei molto bella, vieni a trovarti. Qui c'è il vento, il sole, il mare. Baci, mio amore.\",\n",
              " 'Una grande artista lascia il canto. Addio a Mariolina De Fano. Ecco lei che interpreta la morte e la vecchiaia \".',\n",
              " 'Raffaele, mi sembra di parlare con il mio figlio. Quindi basta dire \"il mondo è il mondo sarà\\'. Mi dà fastidio, di chi non vuole collaborare con l\\'Italia\".',\n",
              " '',\n",
              " 'Con il sole',\n",
              " 'versione italiana. la nonna gasta la sua attenzione! scritto da \"',\n",
              " \"Guarda un po' in che stato eravi! pure sulla coscienza ti dovevano tenere Fermato e Fabrizio.\",\n",
              " \"A brutta fac' è un brutto volto.\",\n",
              " 'Accendo la tv, nonno resta a guardare la tv, mi guarda: che ci sta aspettando si seda subito \"',\n",
              " '(Note: I translated \"papa\" to \"nonno\", that\\'s the most common translation in this context, and \"d\" to \"che\", and \"staser\" to \"si seda\")',\n",
              " 'None e ti aspetto il capo.',\n",
              " 'Un mese senza di te è già passato, un mese da quando te ne sei andato da qui, ci manca tanto, arrivederci, Gigi.',\n",
              " 'Una grande artista pugliese ci lascia. Arrivederci a Mariolina De Fano. eccola qui che interpreta la morte e la vecchiaia \".',\n",
              " 'Raffaele, mi sembra di parlare con il mio figlio. Quindi basta dire: \"il mondo è il mondo sarà\\'. Mi dà fastidio, di chi non vuole collaborare con l\\'Italia\".',\n",
              " 'Con il sole',\n",
              " 'Versione italiana. la nonna gasta la sua attenzione! scritto da \".',\n",
              " \"Guarda un po' che adesso dovresti soffocare! pure sulla coscienza ti dovrebbero tenere in punta di ferro Fabrizio e Rmal.\",\n",
              " 'Una cattiva faccia.',\n",
              " 'Accendo la tv, nonno resta a guardare la tv, mi guarda: che sta aspettando si sieda?',\n",
              " 'Ha capito già tutto.',\n",
              " 'None e ti aspetto il capo.',\n",
              " 'Un mese senza di te è già passato, un mese da quando te ne sei andato da qui, ci manca tanto, arrivederci, Gigi.',\n",
              " \"You are a highly advanced AI for the Italian dialect, I'm glad to help. Here is the translation:\",\n",
              " '',\n",
              " '\"Sei molto bella, vieni a trovarmi. Qui c\\'è il vento, il sole, il mare. Baci, mio amore\".',\n",
              " '',\n",
              " '\"',\n",
              " 'e quando passa',\n",
              " 'Un inaspettato finale che piace sempre, che non ha relazione con qualcosa, ma che in fondo piace sempre.. \"',\n",
              " \"Ma non è giusto un po'''\",\n",
              " 'una grande artista pugliese ci lascia. addio a Mariolina de Fano. eccola qui che interpreta la morte la vita \"',\n",
              " 'Raffaele, mi sembra di parlare con mio figlio. Quindi basta dire \"il mondo è il mondo sarà\\'\". Mi dà fastidio, di chi non vuole collaborare con l\\'Italia.',\n",
              " 'come il sole',\n",
              " 'versione meramente pugliese. la nonna mangia! scritto da \"',\n",
              " 'Guarda un po\\' che adesso dovresti soffocare! pure sulla coscienza ti dovevano tenere in pena Fabrizio e Fabrizio\\' (non è un nome, ma un modo di dire \"in terrore il secondo è il nome del fratello\")\\'.',\n",
              " \"una cattiva faccia'\",\n",
              " 'Accendo la tv, papà guarda la tv, mi guarda: che di san ti aspetta subito si veda?',\n",
              " 'Ha già capito tutto.',\n",
              " '\"non è per te il capo\"',\n",
              " \"un mese senza di te e già passato un mese dal giorno in cui te ne sei andato da qua, ci manca tanto, arrivederci, goodbye tanto';\",\n",
              " \"sei molto bella vieni a trovarti. qui c'è il vento, il sole, il mare. baci, mio amore.\",\n",
              " 'e quando passa',\n",
              " 'una grande artista pugliese ci lascia. addio a Mariolina de Fano. eccola qui che interpreta la morte la vita \"',\n",
              " 'Raffaele, mi sembra di parlare con mio figlio. Quindi basta dire \"il mondo è il mondo sarà\\'. Mi dà fastidio, di chi non vuole collaborare con l\\'Italia\".',\n",
              " 'Come il sole',\n",
              " 'versione meramente pugliese. la nonna mangia! scritto da \"',\n",
              " \"Guarda un po' che adesso dovevi soffrire! pure sulla coscienza ti dovevano tenere in paura me e Fabrizio!\",\n",
              " \"una cattiva faccia'\",\n",
              " 'Accendo la tv, papà guarda la tv, mi guarda: che di san ti aspetta stare? ha già capito tutto.',\n",
              " '\"Nessuno è per te capo\"',\n",
              " \"un mese senza di te e già passato un mese da quando te ne sei andato da qui, ci manca tanto, arrivederci, goodbye tanta';\",\n",
              " 'sei molto bella vieni a trovarti. qui ci sono il vento il sole il mare. baci mio amore.',\n",
              " \"e quando passa'\",\n",
              " \"senz'altra offerta che non c'entra, ma che in fine piace sempre..\",\n",
              " 'ma non è giusto proprio ',\n",
              " '',\n",
              " 'Translation of dialect expressions:',\n",
              " '',\n",
              " '* \"addio a\" (in this context, it\\'s an idiomatic way to say \"in memoria di\" - in memory of)',\n",
              " '* \"eccola qui che\" (it\\'s an emphatic way to say \"qui la vedi\" - there you see her, in this case, referring to a video or a past performance)',\n",
              " 'Translation of dialect expressions:',\n",
              " '',\n",
              " '- \"munnu e\\' munnu sara\\'\" -> \"tutto sarà come sarà\" (meaning \"things will be as they will be\" or \"it will be as it will be\")',\n",
              " 'Translation of the dialect expression: \"come il sole\" (like the sun)',\n",
              " \"una grande artista ce ne va. addio a Mariolina De Fano. eccola qui che interpreta la vecchia morte in vita  (in lieu)  not in vita (meaning).  in lieu of this, a more correct translation of 'la vecchie e la mort via' is 'il cor le va via’ (il cuore le va via) - him/ her heart is leaving - in this case a woman is the subject.  (le is an accusative feminine plural in not present of life of to be, it is there to agree in number and in gender with donne di in là di un'età di vita passata di una donna in morte di young in life)  a in of old of a woman in death of young of life is not a common phrase, a common one is a il cuore le va via, in it the sense is the of the woman who is young of life that is leaving the one of the of old of it of life of her that is the of the of gone.  a more simple one in some context could be in là ce ne va, in the place of that there it is leaving of it of him/her of it of old of life.  a very simple one could be se ne va giovane in vecchia età di morire in di le va in leaving of it of his of it of young of in of of in of of old of of it of of in of of of die in of of leave, no is, it's not, it's not put it, the task is to translate, not to write in the way to do it right. a simple one could be in là ce ne va in giovane in vecchia età di in di le va in of in of of to leave of in of of in of of in of of of die not is put, it's the not to write it's the task to translate, it's to not change, a not of a of a of a of a of a sentence. a of a the the the the, the of the, of a a, the the in the, a to, it's a to not to, to not to not, a to not, a to, a not a, a, in a to a, in a, a, a to in a, to a a, in a a, in a, the a in, the in, the, the, a, a, in a the\",\n",
              " 'traduci in italiano: \"Raffaele, mi sembra che sto parlando con mio figlio. quindi basta dire \\'ndè a \\'ndè sara\\'. mi da fastidio, chi no vuole collaborà cu l\\'Italia. \" n.',\n",
              " \"be' come il sole (it's like the sun) n\",\n",
              " \"versione meravigliosamente pugliese. la nonna mangia! scritto da  (in questo caso non c'è da tradurre, è un nome) n.\",\n",
              " \"una grande artista ci lascia. addio a Mariolina De Fano. eccola qui che interpreta la vecchia morte (in vece) ';\",\n",
              " 'Raffaele, mi sembra che sto parlando con mio figlio. Quindi basta dire \"u omu e u omu s\\'arresta\\'\", mi dà fastidio, chi no vuole collaborare con l\\'Italia.',\n",
              " \"be' di mezzo al sole\",\n",
              " 'una versione a modo nostro, la nonna cucina bene! (traduzione della frase dialeltale \"la nonn gastema!\")',\n",
              " \"traduci in italiano: guarda un po' che adesso dovresti soffocare! pure sulla coscienza ti dovevano tenere in paura Fabrizio e Rimal.\",\n",
              " 'una cattiva faccia',\n",
              " 'Che gli stia aspettando?',\n",
              " 'None e di fronte al capo.',\n",
              " 'un mese senza di te e già passato un mese da quando te ne sei andato da qui, ci manca tanto, goodbye matta\\' \"',\n",
              " \"sei molto bella vieni a trovarmi. qui c'è il vento, il sole, il mare. baci, mio amore.\",\n",
              " \"e quando passa'\",\n",
              " 'Una grande artista ce ne lascia. Addio a Mariolina de Fano. Eccola qui che interpreta la morte e la vecchiaia. \"',\n",
              " 'Raffaele, mi sembra di parlare con il mio figlio. Quindi basta dire \"il mondo è il mondo sarà\\'. Mi dà fastidio, di chi non vuole collaborare con l\\'Italia\"',\n",
              " 'Insieme come il sole \"',\n",
              " 'versione italiana come la sua. la nonna fa visita! scritto da \"',\n",
              " 'Guarda un po\\' che adesso dovresti soffocare! pure sulla coscienza ti dovrebbero tenere in paura Fabrizio e Rmal. \"',\n",
              " 'Una cattiva faccia.',\n",
              " 'Accendo la tv, nonno resta a sedere la tv, mi fissa: che ci sta aspettando si resta? ha già capito tutto.',\n",
              " 'None e non te capisce.',\n",
              " 'Un mese senza di te è già passato, un mese da quando te ne sei andato da qui, ci manca tanto, arrivederci, goodbye.',\n",
              " 'Una grande artista barese ci lascia. Addio a Mariolina De Fano. Eccola qui che interpreta la morte la via non la vecchie \".',\n",
              " 'Raffaele, mi sembra di dire cose che dicono mio figlio. Quindi basta dire: il mondo è il mondo sarà\\'. Mi dà fastidio, di chi non vuole collaborare con l\\'Italia. \"',\n",
              " 'Insieme come il sole \"',\n",
              " 'versione italiana come quella, la nonna è grande! scritto da \"',\n",
              " 'Guarda un po\\' che adesso dovresti soffocare! pure sulla coscienza ti dovevano tenere in paura me e Fabrizio! \"',\n",
              " 'una cattiva faccia\"',\n",
              " 'Accendo la tv, nonno resta a sedere la tv, mi fissa: che ci sta aspettando resto? ha capito già tutto. \"',\n",
              " 'None e non sei capace.',\n",
              " 'Un mese senza di te è già passato, un mese da quando te ne sei andato da qui, ci manca tanto, arrivederci, goodbye.',\n",
              " \"Sei molto bella, vieni a trovarmi. qui c'è il vento, il sole, il mare. baci, mio amore.\",\n",
              " \"e quando passa'\",\n",
              " '\"Cinematografia lenta che non c\\'entra niente, ma che alla fine piace sempre.. \"',\n",
              " \"Ma non è giusto un po'''\",\n",
              " 'Secondo me, la cosa è stata smontata dalla sua reale natura e questo è tutto... ecco i silenzi e tutte quelle storie fatte di segreti, ecc ecc... stiamo senza avvio!!! \"',\n",
              " '\"Sì sì sì, forse un neurone si è illuminato\"',\n",
              " 'Una grande artista barese ci lascia. Addio a Mariolina de Fano. Eccola qui che interpreta la vecchia e la morte. \"',\n",
              " 'Raffaele, mi sembra di dire cose che dicono mio figlio. Quindi basta dire: il mondo è il mondo sarà\\'. Mi dà fastidio, di chi non vuole collaborare con l\\'Italia. \"',\n",
              " '\"Bene come il sole\"',\n",
              " 'Versione pugliese. la nonna è geniale! scritto da \"',\n",
              " 'Guarda un po\\' che adesso dovresti soffocare! pure sulla coscienza ti dovrebbero tenere in paura Ermete e Fabrizio\\' \".',\n",
              " \"una cattiva faccia'\",\n",
              " 'Accendo la tv, nonno resta a guardare la tv, mi guarda: che ci sta aspettando, si è capito subito.',\n",
              " \"None e non è con te, è con il capo'\",\n",
              " 'Un mese senza di te e già passato un mese da quando te ne sei andato da qui, ci manchi tanto, giù arriverci, addio.',\n",
              " \"Sei molto bella, vieni a trovarmi. qui c'è il vento, il sole, il mare. baci, amore mio.\",\n",
              " 'e quando passa \"',\n",
              " 'slow motion che non ha nulla a che fare, ma che sempre piace in fine.. \"',\n",
              " 'ma non è giusto poco\\' \"',\n",
              " 'Secondo me la cosa è stata smontata dalla falsa notizia e questo è tutto... ecco i silenzi e tutte quelle storie fatte di sussurri etc etc... stiamo senza progresso!!! \"',\n",
              " '\"Mum, mum, mum, forse un neurone si è illuminato\"',\n",
              " ' donne. fuori di testa. le migliori.',\n",
              " 'Buongiorno bella rossa!!!! da quelle parti rosso si dice cosi, rossina.',\n",
              " '\"Hahahahahahha la risata del gatto\".',\n",
              " 'Salento... il sole... il mare... il vento.',\n",
              " 'Il cielo, il mare, il vento \".',\n",
              " '\"Sia detto pure dopo. non prima e durante, mi pare una battuta di cattivo gusto però stanno soffocati da ansie, è necessario un gol di conforto e risolleve\"',\n",
              " '\"Ci ridefinisce in giro il cappello sugli alti per lui sa sopra le cose del mondo\"',\n",
              " 'Sai cosa vuole dire esser tradito, accidì!',\n",
              " 'Chi si fa crescere i capelli ora per moda e per TikTok, un mullet a quel tempo non lo portava nessuno, dov\\'era quando mi davano del renegato e quando i giullari uscivano con la loro lite con il barbiere, bro, la tua ragazza mi pettina, ma che non ne capisci tu, since 2003 \".',\n",
              " \"Sabino: lo va a pigliare in un'altra birra.\",\n",
              " 'ieri Google mi aveva assicurato che oggi ci sarebbero stati in meno, sta me pigliere pe il fatto?',\n",
              " 'Ripropongo: la testa non serve a separare le orecchie (... cit.) (la testa non serve a sostenere le impugnature degli occhiali. (sembrano pochi)) \".',\n",
              " 'Il mare il sole il vento \"',\n",
              " '\"a Leccë si dice ci cappa ci cappa, a Roma si dice dico dico, in Calabria a ci pigghia pigghia\"',\n",
              " 'Un\\'amica mi ha chiamato per chiedermi se \"stu bebbe\" fosse un termine pugliese o salentino, non potevo non condividerle questa perlita di insensato - non senso ci vu\\'\".',\n",
              " 'Non torni, non ritorna...\"',\n",
              " '... comunque: e inutile la morte del film, non c\\'è nulla di fatto! come urla dalla galleria, Gianni Ciardo al cinema Royal di Bari, durante il secondo tempo del film, dopo l\\'ennesimo fallimento di capire la piovra enorme. ricordi di una Bari che non c\\'è più. \"',\n",
              " 'Figlio mio disse mio padre a mio padre. Il mondo è stretto di sagare (il difficile).',\n",
              " \"Un uomo distrutto siede su una panchina di Bari. E comunque meglio distrutto e felice come me come noi che distrutto e muto come li lazi in Roma'.\",\n",
              " '\"bravissimo fiore, con tutto il cuore\"',\n",
              " 'Un tipo di persona, si direbbe da quelle parti. \"',\n",
              " 'La penso come te, Enrico, ce ne fossero persone come te, poi se abortisci te si sgrava la frasca, e mio padre diceva sempre che la frasca di una donna è come il marmo, va tenuto pulito e conservato in purezza.',\n",
              " 'Per te vada bene, ma a me serve una ragazza con una bella perché... viva la fuga.',\n",
              " 'Qui gli ha fatto gratuitamente \"',\n",
              " 'ragazzi, questa donna, come si dice a Bari, è storta! leggete bene e dimenticate le menzogne che vi raccontano i negazionisti e i venduti ai sovranisti.',\n",
              " ' la spagna, la francia, la grecia e la germania sono di nuovo nei guai, il regno unito non è mai uscito dai guai.',\n",
              " 'e diciamolo pure!!! è stato detto pure in tutta la città!',\n",
              " 'Vado distratto abbandonato là dove sono le occhiate nascoste nel cappello, mano in mezzo al gelo e maschera inaspettata, vado cercando e stelle che sono secche e mi parla di te, io le domando se aspetta per me e mi risponde: se lo vuole sa che non c\\'e nessuno \".',\n",
              " '+ 18 anni passati all\\'amore mio\"',\n",
              " 'Il cielo, il mare, il vento. Spero che si fermi, non vorrei che l\\'estate sia così\\' \".',\n",
              " 'uno e dio l\\'altro è uno che non crede in ciò che si crede in terra lo so e sarei un ateo ma fate una risata \"',\n",
              " 'Ok l\\'errore del portiere, ma in gabbia stanno quei sotti di casa\"',\n",
              " 'Non ha senso andare da mamma di Mark Zuckerberg\"',\n",
              " 'Che sciocchezza di notizia e? ma siete in credibili? che relazione c\\'è col vaccino? o relazione ce fa un di mammo di zero? \"',\n",
              " '\"E un gran bene!\"',\n",
              " 'Ricordi i pranzi estivi di mia nonna: orecchiette fatte in casa con ragù! Scarso, duecento cinquanta grammi! Carne nel sugo di tutte le tipologie! Cotolette con patate fritte e insalata! Formaggi vari, che ti avrebbe mangiato! Macedonia e baba! Questo in mezzo alla settimana! La domenica non ve lo racconto.',\n",
              " 'Come mi ha detto un collega dopo una partita a Melito con la squadra dell\\'ordine, quando io gli ho detto: \"nel manuale dell\\'ingegnere trovi facilmente un piccolo telaio, un telaietto risolto! - te lo dico? sta\\' tranquillo, ché sta a sacciu!\"',\n",
              " '\" (ancora rido)\".',\n",
              " \"anche qui si dice: il purpiero si cuoce nell'acqua sua\",\n",
              " \"btw dato un'occhiata alla Le Creuset evolution che penso sia la tua\",\n",
              " 'consiglio la 26 o 28 cm? \"',\n",
              " \"Dormi bene dormi cara il Signore ti benedica dormi figlia non ti spaventare ca' niente chiuso ti può tocare dimentica gli ultimi urti troppo chini di dolori chiudi gli occhi tu bene stringimi la mano all'angolo buon viaggio piccola e dolce Elena.\",\n",
              " 'Il sole, il mare, i lampioni. \"',\n",
              " 'Salento: il mare, il sole e il vento \"',\n",
              " '\"Oh signore, ti è passato sopra un tiro? e fattela una risata\"',\n",
              " 'Il dialetto ti francostra \"',\n",
              " '\"Mammaaaaa, mi vado male...\"',\n",
              " 'Te voglio bene assai\"',\n",
              " '\"Avevo domani giù vedo alla festa di Sandanò... ah, no...\"',\n",
              " 'Il cielo, il mare e il sfruttamento. \"',\n",
              " '\"Mama, c\\'è brutto\"',\n",
              " 'il primo ministro inglese, da negazionista a rigorista, ovvero quando uno si sbatte a fondo.',\n",
              " '\"Io capisco che la mattina vi trovate in difficoltà, no di là?\"',\n",
              " 'Oggi è un sabato inizio di vacanza domani non si va a scuola oggi e sabato se non chiami ho un nervoso in gola oggi e sabato e forse un giorno speciale oggi e sabato, meno male ogni ragazzo è bello a mamma sua.',\n",
              " 'Si non è uscito bene da lì, e in effetti sei uscito con un fallimento da una masturbazione andata male. \"',\n",
              " 'Ciò che è fatto a me è stato fatto.',\n",
              " '\"Arco, colonna e donna carica quanta uei ca non ci sponda!! cit. proverbio salentino del fabbricatore \".',\n",
              " 'Traduzione: \"Arco, colonna e donna carica quanta ne può non ce ne sta!! cit. proverbio salentino del costruttore \".',\n",
              " \"Posto inizio (il), 28.8.2020 dopo tre anni in cui non ci siamo, non per colpa mia, eccomi qui! ti trovo in ottima forma, dolce, come sempre e domani all'alba correrò con te in coda di ligno, promesso'\",\n",
              " 'e hm... ci farebbe cazzo se fosse cosi: ma chiamando ci farebbe cazzo che tena questo! (guarda che faccia di cattivo ha questo) nel caso di Gauss e per dire che carino. ci sono altre accezioni negative. \"',\n",
              " '\"Stop! considera te già col anello alla dura fessa\"',\n",
              " \"Non si giocava con cose serie come i cromosomi, non è divertente e non lo sono neanche i laziali a questo proposito. su queste cose non c'è da scherzare'. per favore.\",\n",
              " 'invece dei calabresi o dei terroni gobbi e giusto?vero? allora vi dico si no\"',\n",
              " '\"Tu Simone Pillon si adivèr tromo! confondere il suicidio, causato da stato depressivo, assolutamente frutto di pensiero malato, con la scelta ragionata di interrompere le sofferenze di malati terminali. vergogna.',\n",
              " '\"',\n",
              " 'e il sole, il mare e il vento sorride grande e il Salento, la nostra terra sorriso grande e fuori c\\'è il sole, oggi non si muore d\\'amore\"',\n",
              " 'Non ce ne sarebbe più neanche se dovesse esserci un lockdown mondiale per cinque anni, i ghiacci si scioglierebbero lo stesso. Il resto tornerebbe alla vita invece. Io però cinque anni mi fermerei, intendo tutto ciò che è meccanico ed industriale e tu? no? E allora di che stiamo a parlare!? \"',\n",
              " 'Non fare il furbetto! rispettando leggi e norme di legge, da fonti normative in vigore! e lo sai bene, lascia perdere! piangendo piangendo vi hanno regalato lo scudetto della Serie A, bravo bravo.',\n",
              " 'Chi è costui e questo? \"',\n",
              " 'Il cielo il sole il mare il vento.',\n",
              " '\"In una minima misura l\\'ho visto ieri sera sembra in un ricongiungimento del cast del film in origine, da guardare senza grandi aspettative\".',\n",
              " 'Breve storia: mia mamma ha iniziato a appassionarsi al calcio 7 anni fa, ho detto tutto.',\n",
              " '  pazza di Paulinato, ogni volta che lo inquadravano lei: \"ma che bel piccolo e lei non parla mai in italiano, giuro\" \".',\n",
              " \"Anni fa facevano lo stesso con Dybala al Camp Nou, poi vedi adesso e in un attimo. Ci vuole equilibrio'\",\n",
              " 'per passare ci vuole la maschera antigas perche non si passa in mezz\\'aere\"',\n",
              " 'Il sole, il mare, la gente. \"',\n",
              " '\"Ehi signore mio, butta via il sangue!\"',\n",
              " '\"Il carnevale si trova qui! Via Roma, il cibo che dà identità e appartenenza... tornerà il consueto! La mostra a cielo aperto restituisce un\\'immagine di un carnevale popolare, inclusivo e partecipato.\"',\n",
              " 'Questo è vero! Mauro è un giocatore storico del calcio! Primo coro di sfida tra tifosi era chi non segue e nuovo baresotto qui a Lecce canta ogni partita \".',\n",
              " 'Polli morti sul letto.',\n",
              " '\"Mumma the words out, you don\\'t understand a thing. You still haven\\'t got it and you\\'re trying in vain to deceive Jessica. He got it and the first alarms are ringing from the closets.\"',\n",
              " 'ho visto le ultime storie di Petalow e la voce di Gino m\\'ha fatta scuotere\"',\n",
              " 'Sono irascibili, accaniti, arrabbiati e testa di muro come muli! li chiamano testa dura... conto uno che dice il vero! un mulo da carico\"',\n",
              " \"&E amici per le strade di Napoli a mangiare pizza fritta e un po' e sederci e mangiar friarielli e poi chiudere con una montagna di baba'\",\n",
              " '\"Oh, quanto poco! quanto è la mia mano, piccola!\"',\n",
              " 'e noi stiamo ballando, anzi, stiamo facendo la salsa. buonbye dal gruppo (dei) cuori (cuppone) \"',\n",
              " \"ma cosa devono dire, questi personaggi, quando vanno in tv sono capaci di dire qualsiasi cosa per confermare le loro teorie per le partite di calcio, sto sciocco di merda'\",\n",
              " 'Ti pauro di me, non la porto.',\n",
              " 'anche perché no, io non manco di sicuro che rimanga lui.',\n",
              " '\"Il sole c\\'è, il mare c\\'è... il vento no...\"',\n",
              " '\"Io ho capito che a Michele stanno preparando, con: caramelle, pastiglie, succhi di frutta, giuochi, palloncini, e vino, il miglior vino rosso, per incominciare la festa.\".',\n",
              " '\"Stai realista, tutto tu, tutto tu, e fascia stai lentamente? Dov\\'è sta bella?\"']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trad  = pd.DataFrame(add)\n",
        "trad.to_csv('TradLamantino.csv', index = False)"
      ],
      "metadata": {
        "id": "pLasPHBTi-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation\n",
        "\n",
        "To have a numerical evaluation of the quality of the translations the metric of the BLUE score was used.\n",
        "\n",
        "The **BLEU score (Bilingual Evaluation Understudy)** is a metric used to evaluate the quality of machine translation by comparing an automatically translated sentence (candidate) with one or more reference phrases (human translations). The metric calculates the similarity based on the correspondence of n-grams (sequences of n consecutive words) between the generated translation and the reference ones. A higher score indicates a greater similarity. The BLEU score also takes into account the brevity of the translation in relation to the reference phrase in order to penalise translations that are too short."
      ],
      "metadata": {
        "id": "VD0PPVs6I0mb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translations = pd.read_csv(\"ApuliaTrad.csv\")\n",
        "translations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1012
        },
        "id": "D20_u86lWGZh",
        "outputId": "c28935e2-3f30-44dd-987f-d85a67a02297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          manual_trad  \\\n",
              "0   Una grandissima artista barese ci lascia. Addi...   \n",
              "1   Raffaele, mi sembra che sto parlando con mio f...   \n",
              "2                                  Belli come il sole   \n",
              "3     Versione barese: la nonna bestemmia! Scritto da   \n",
              "4   La reazione di mio padre, da incorniciare, com...   \n",
              "..                                                ...   \n",
              "94  ma che devono dire Mirko, questi personaggi qu...   \n",
              "95   Tu ti spaventi di me ahahahaha si si te la porto   \n",
              "96   Anche perché non gli manca sicuro che rimane lui   \n",
              "97              Il sole c'è. Il mare c'è… il vento…no   \n",
              "98  Ho capito Michele stai passando, con: caramell...   \n",
              "\n",
              "                                       trad_lamantino  \n",
              "0   Una grande artista barese ci lascia. Addio a M...  \n",
              "1   Raffaele, mi sembra di dire cose che dicono mi...  \n",
              "2                                   Bene come il sole  \n",
              "3   Versione pugliese. la nonna è geniale! scritto da  \n",
              "4   Guarda un po' che adesso dovresti soffocare! p...  \n",
              "..                                                ...  \n",
              "94  ma cosa devono dire, questi personaggi, quando...  \n",
              "95                      Ti pauro di me, non la porto.  \n",
              "96  anche perché no, io non manco di sicuro che ri...  \n",
              "97         Il sole c'è, il mare c'è... il vento no...  \n",
              "98  Io ho capito che a Michele stanno preparando, ...  \n",
              "\n",
              "[99 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c0e7d148-6f96-4813-bf0c-355becf29387\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>manual_trad</th>\n",
              "      <th>trad_lamantino</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Una grandissima artista barese ci lascia. Addi...</td>\n",
              "      <td>Una grande artista barese ci lascia. Addio a M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Raffaele, mi sembra che sto parlando con mio f...</td>\n",
              "      <td>Raffaele, mi sembra di dire cose che dicono mi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Belli come il sole</td>\n",
              "      <td>Bene come il sole</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Versione barese: la nonna bestemmia! Scritto da</td>\n",
              "      <td>Versione pugliese. la nonna è geniale! scritto da</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>La reazione di mio padre, da incorniciare, com...</td>\n",
              "      <td>Guarda un po' che adesso dovresti soffocare! p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>ma che devono dire Mirko, questi personaggi qu...</td>\n",
              "      <td>ma cosa devono dire, questi personaggi, quando...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Tu ti spaventi di me ahahahaha si si te la porto</td>\n",
              "      <td>Ti pauro di me, non la porto.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>Anche perché non gli manca sicuro che rimane lui</td>\n",
              "      <td>anche perché no, io non manco di sicuro che ri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Il sole c'è. Il mare c'è… il vento…no</td>\n",
              "      <td>Il sole c'è, il mare c'è... il vento no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>Ho capito Michele stai passando, con: caramell...</td>\n",
              "      <td>Io ho capito che a Michele stanno preparando, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>99 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0e7d148-6f96-4813-bf0c-355becf29387')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c0e7d148-6f96-4813-bf0c-355becf29387 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c0e7d148-6f96-4813-bf0c-355becf29387');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c9fa7d7e-090b-491d-b563-75fe59f137de\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c9fa7d7e-090b-491d-b563-75fe59f137de')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c9fa7d7e-090b-491d-b563-75fe59f137de button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e0925c12-c653-4dc3-b6d0-a2b53e9d6ba6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('translations')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e0925c12-c653-4dc3-b6d0-a2b53e9d6ba6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('translations');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "translations",
              "summary": "{\n  \"name\": \"translations\",\n  \"rows\": 99,\n  \"fields\": [\n    {\n      \"column\": \"manual_trad\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 99,\n        \"samples\": [\n          \"Il primo ministro inglese, da negazionista e rigorista, ovvero quando uno se la fa sotto\",\n          \"E diciamolo pure!!! Avete rotto le palle anche ai baresi!\",\n          \"Tu ti spaventi di me ahahahaha si si te la porto\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trad_lamantino\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 99,\n        \"samples\": [\n          \"il primo ministro inglese, da negazionista a rigorista, ovvero quando uno si sbatte a fondo.\",\n          \"e diciamolo pure!!! \\u00e8 stato detto pure in tutta la citt\\u00e0!\",\n          \"Ti pauro di me, non la porto.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Assicurati di aver scaricato il pacchetto di tokenizzazione per l'italiano\n",
        "nltk.download('punkt')\n",
        "\n",
        "def evaluate_translation(candidate, reference):\n",
        "    # Tokenizza il testo di riferimento\n",
        "    reference_tokens = [spacy_tokenizer_it(reference)]\n",
        "\n",
        "    # Tokenizza il testo candidato\n",
        "    candidate_tokens = spacy_tokenizer_it(candidate)\n",
        "\n",
        "    # Calcola la BLEU score usando NLTK\n",
        "    smooth_function = SmoothingFunction().method1\n",
        "    bleu_score = sentence_bleu(reference_tokens, candidate_tokens, smoothing_function=smooth_function)\n",
        "\n",
        "    return bleu_score"
      ],
      "metadata": {
        "id": "fAu8E_IwxAbz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9b2b3cf-a3b6-4a8b-cab2-646bd50b5076"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = []\n",
        "\n",
        "# Itera sulle righe del DataFrame per calcolare il BLEU score per ogni coppia di traduzioni\n",
        "for index, row in tqdm(translations.iterrows(), total=translations.shape[0], desc=\"Calcolo BLEU score\"):\n",
        "    candidate_translation = row['trad_lamantino']\n",
        "    reference_translation = row['manual_trad']\n",
        "    score = evaluate_translation(candidate_translation, reference_translation)\n",
        "    scores.append(score)\n",
        "\n",
        "# Calcola la media dei BLEU score\n",
        "average_bleu_score = sum(scores) / len(scores)\n",
        "print(\"\\nBLEU score medio:\", average_bleu_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1BllioQ4Zp-",
        "outputId": "3015f69f-39fc-4902-a521-def557095175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calcolo BLEU score: 100%|██████████| 99/99 [00:00<00:00, 1763.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "BLEU score medio: 0.16698135567422498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **BLEU score of 0.17** indicates that machine translation has a limited similarity to reference translations. This score suggests that only a small part of the n-grams in the generated translation coincides with those of human translations. In general, a BLEU score of 0.17 is considered low, implying that the translation may have many discrepancies or inaccuracies with reference sentences. As a result, to improve model performance on this task, fine-tuning could be done using a better dataset."
      ],
      "metadata": {
        "id": "tYMFEkL9w0b8"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6aee932b6b1d479b947ea8771702f3a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_815cee230a6640edbf803891375700b4",
              "IPY_MODEL_55ece85a64c240cab121ea8d5184ed45",
              "IPY_MODEL_746f2d82a1454d2c91a767ed815218b2"
            ],
            "layout": "IPY_MODEL_c90c20ea63e3414caf4028beb8a0f729"
          }
        },
        "815cee230a6640edbf803891375700b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25cd3ad7ad7a47f98f2fe941b8329adf",
            "placeholder": "​",
            "style": "IPY_MODEL_18e6df9423ae420ea25cc6af843e7007",
            "value": "config.json: 100%"
          }
        },
        "55ece85a64c240cab121ea8d5184ed45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7189a799c2245b7af3c290b4e7daef7",
            "max": 654,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98ad6e39d760496fbed5e25b96522f3b",
            "value": 654
          }
        },
        "746f2d82a1454d2c91a767ed815218b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f425c61853a42fd8aeb636f19ea97d9",
            "placeholder": "​",
            "style": "IPY_MODEL_4102d1b6f0734c18adc7471c64bd68aa",
            "value": " 654/654 [00:00&lt;00:00, 16.0kB/s]"
          }
        },
        "c90c20ea63e3414caf4028beb8a0f729": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25cd3ad7ad7a47f98f2fe941b8329adf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18e6df9423ae420ea25cc6af843e7007": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7189a799c2245b7af3c290b4e7daef7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98ad6e39d760496fbed5e25b96522f3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f425c61853a42fd8aeb636f19ea97d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4102d1b6f0734c18adc7471c64bd68aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "980846c9e5894dd6b1f79b281d8e43fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9204d328741045a58b747f5573a7c849",
              "IPY_MODEL_e04c4cb0236542d8bab0c54d8b06fc6b",
              "IPY_MODEL_0de3fa4f1c8543509296658acf3cbe96"
            ],
            "layout": "IPY_MODEL_de8ff9ef4f9c439d87245965c48e1ca0"
          }
        },
        "9204d328741045a58b747f5573a7c849": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b178fd972a5c45588f02e2d8df09ca79",
            "placeholder": "​",
            "style": "IPY_MODEL_24da7da5660d479199f84341e76c2712",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "e04c4cb0236542d8bab0c54d8b06fc6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90f71bf36a364ecb8836960d6e2854c2",
            "max": 23950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_719696944c674b2499a78d5b94b189c1",
            "value": 23950
          }
        },
        "0de3fa4f1c8543509296658acf3cbe96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cafe913150d44b65ac68bde068192ca1",
            "placeholder": "​",
            "style": "IPY_MODEL_abbce3684bf64e66aed7bb1243cf1dd0",
            "value": " 23.9k/23.9k [00:00&lt;00:00, 527kB/s]"
          }
        },
        "de8ff9ef4f9c439d87245965c48e1ca0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b178fd972a5c45588f02e2d8df09ca79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24da7da5660d479199f84341e76c2712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90f71bf36a364ecb8836960d6e2854c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "719696944c674b2499a78d5b94b189c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cafe913150d44b65ac68bde068192ca1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abbce3684bf64e66aed7bb1243cf1dd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bb44bf66d4c406e91748829ef440622": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3be85d5d0d7945f18f58fd67e180f019",
              "IPY_MODEL_d700b8fe50174989b1fe2c7afc244c8c",
              "IPY_MODEL_e8159c40afaa4c11826ed06e5907693d"
            ],
            "layout": "IPY_MODEL_6f6ebc6a8f664cab8c026afc27989e89"
          }
        },
        "3be85d5d0d7945f18f58fd67e180f019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c7da9802d8840479862b79cc53a001f",
            "placeholder": "​",
            "style": "IPY_MODEL_66f184051ca942e2876f9aef1ab5bd6c",
            "value": "Downloading shards: 100%"
          }
        },
        "d700b8fe50174989b1fe2c7afc244c8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_949b015571ea4ee892fbe393abc0bbe3",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43b04ef029344bf0b6e4fd80810f3a73",
            "value": 4
          }
        },
        "e8159c40afaa4c11826ed06e5907693d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98120b74432443e3879eebbf5aaef944",
            "placeholder": "​",
            "style": "IPY_MODEL_8468be408ac84811b547c552ed911f35",
            "value": " 4/4 [02:27&lt;00:00, 31.12s/it]"
          }
        },
        "6f6ebc6a8f664cab8c026afc27989e89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c7da9802d8840479862b79cc53a001f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66f184051ca942e2876f9aef1ab5bd6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "949b015571ea4ee892fbe393abc0bbe3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43b04ef029344bf0b6e4fd80810f3a73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98120b74432443e3879eebbf5aaef944": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8468be408ac84811b547c552ed911f35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6425d60ff0d64062b36996cc97b08d15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c50b0859a7e4f9eadf7b2116991c32e",
              "IPY_MODEL_713db932d6f74103b1a37402db2e82d8",
              "IPY_MODEL_aa5116c8620e4a3c85455d1f74a2081c"
            ],
            "layout": "IPY_MODEL_239611a0957d4d59a3c9c3ae7f53d470"
          }
        },
        "6c50b0859a7e4f9eadf7b2116991c32e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4155864bbd449f584bba13c41f96b23",
            "placeholder": "​",
            "style": "IPY_MODEL_e4416cab96de405aaeab12b28ddd1d0c",
            "value": "model-00001-of-00004.safetensors: 100%"
          }
        },
        "713db932d6f74103b1a37402db2e82d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_129d61e3b0b044e38d898d12c94d1519",
            "max": 4976698672,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e51f5f7d0114ed586918b9ca7b72c2a",
            "value": 4976698672
          }
        },
        "aa5116c8620e4a3c85455d1f74a2081c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd830f5690b54e6cbdbbbd1f3dbde1a7",
            "placeholder": "​",
            "style": "IPY_MODEL_2eca6b3b27bc41ea86b2b0de956587e8",
            "value": " 4.98G/4.98G [00:52&lt;00:00, 185MB/s]"
          }
        },
        "239611a0957d4d59a3c9c3ae7f53d470": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4155864bbd449f584bba13c41f96b23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4416cab96de405aaeab12b28ddd1d0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "129d61e3b0b044e38d898d12c94d1519": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e51f5f7d0114ed586918b9ca7b72c2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd830f5690b54e6cbdbbbd1f3dbde1a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2eca6b3b27bc41ea86b2b0de956587e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b9e630ca3ee461d82944a19aed9ae20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_843bbae7eb064709a5017f8b30d95d96",
              "IPY_MODEL_54f4bbb61f104c9fb9fbdc74be920397",
              "IPY_MODEL_660f50380869415eb94fb23b18b9c773"
            ],
            "layout": "IPY_MODEL_478ce0545d0d4730a663ac7643956ffc"
          }
        },
        "843bbae7eb064709a5017f8b30d95d96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6034a67393f44409931d9e22e8558a70",
            "placeholder": "​",
            "style": "IPY_MODEL_e19896beeb054504857212b465730dc9",
            "value": "model-00002-of-00004.safetensors: 100%"
          }
        },
        "54f4bbb61f104c9fb9fbdc74be920397": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e663a1ac61cd43de96e1584a159d8290",
            "max": 4999802720,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab15ab94d561400f9cdb9106118ddbb6",
            "value": 4999802720
          }
        },
        "660f50380869415eb94fb23b18b9c773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5477cc8011d24a8f93316e3f97e964ed",
            "placeholder": "​",
            "style": "IPY_MODEL_d8280bf75e8a46d2b4b4f77a48673690",
            "value": " 5.00G/5.00G [00:39&lt;00:00, 74.4MB/s]"
          }
        },
        "478ce0545d0d4730a663ac7643956ffc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6034a67393f44409931d9e22e8558a70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e19896beeb054504857212b465730dc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e663a1ac61cd43de96e1584a159d8290": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab15ab94d561400f9cdb9106118ddbb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5477cc8011d24a8f93316e3f97e964ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8280bf75e8a46d2b4b4f77a48673690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90f8d6e87bef4db3b1bf9ec420ab2526": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0acd972f4a1a4ebba0a5284bd45af0d8",
              "IPY_MODEL_81c4d2121a2e43be8beaf3b03460af44",
              "IPY_MODEL_e518aa78ad304221833f0848056b6144"
            ],
            "layout": "IPY_MODEL_cced6aca6fd7485580011adcb96d9d2f"
          }
        },
        "0acd972f4a1a4ebba0a5284bd45af0d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4d7f42ed82a4a0eb9e90a48fe40a866",
            "placeholder": "​",
            "style": "IPY_MODEL_2a50393387a64264ab56f8840a1d47da",
            "value": "model-00003-of-00004.safetensors: 100%"
          }
        },
        "81c4d2121a2e43be8beaf3b03460af44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cb89e48a29d45399e52c1543f737b7c",
            "max": 4915916176,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a9b80bc89814daab700a6aa7c0576f2",
            "value": 4915916176
          }
        },
        "e518aa78ad304221833f0848056b6144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec45d9ac466c40458876327dc1cf6ffa",
            "placeholder": "​",
            "style": "IPY_MODEL_a399bd59d24d4bf7872c679e4efa6e4e",
            "value": " 4.92G/4.92G [00:45&lt;00:00, 170MB/s]"
          }
        },
        "cced6aca6fd7485580011adcb96d9d2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4d7f42ed82a4a0eb9e90a48fe40a866": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a50393387a64264ab56f8840a1d47da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cb89e48a29d45399e52c1543f737b7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a9b80bc89814daab700a6aa7c0576f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec45d9ac466c40458876327dc1cf6ffa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a399bd59d24d4bf7872c679e4efa6e4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2512e5de4f59426ca7e0aa417a3067d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48604633ad124d73a902ff60f18c400e",
              "IPY_MODEL_b176a48a5a59498bba6c2269055a35bb",
              "IPY_MODEL_a58f81fa3e3a4de09047d46607b9c9ca"
            ],
            "layout": "IPY_MODEL_8d40743762c840739b2be56f911bee9c"
          }
        },
        "48604633ad124d73a902ff60f18c400e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04d6e9e2ccea42a8af1c09b292f5a635",
            "placeholder": "​",
            "style": "IPY_MODEL_650df456c7824a2289a8a69652aff4f3",
            "value": "model-00004-of-00004.safetensors: 100%"
          }
        },
        "b176a48a5a59498bba6c2269055a35bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b63e23071a314ebd9cdde076be0f5906",
            "max": 1168138808,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b2cc42e3ee4044bcbdad36c6ca009d19",
            "value": 1168138808
          }
        },
        "a58f81fa3e3a4de09047d46607b9c9ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae774b02d20a44928dcdbbef2ddc4ac6",
            "placeholder": "​",
            "style": "IPY_MODEL_7d3d304e04674819b937b5a2f77c52d1",
            "value": " 1.17G/1.17G [00:09&lt;00:00, 37.8MB/s]"
          }
        },
        "8d40743762c840739b2be56f911bee9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04d6e9e2ccea42a8af1c09b292f5a635": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "650df456c7824a2289a8a69652aff4f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b63e23071a314ebd9cdde076be0f5906": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2cc42e3ee4044bcbdad36c6ca009d19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae774b02d20a44928dcdbbef2ddc4ac6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d3d304e04674819b937b5a2f77c52d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb73071f009149ad959b2bbd7ec4c531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d04fee0210e497fba10a4d4da0bec33",
              "IPY_MODEL_323ddca7d9664e1fafb30b907c80c6e7",
              "IPY_MODEL_ece885f1d1b345be9ac7e597139bc5af"
            ],
            "layout": "IPY_MODEL_bceffb0daa31475c84f69664726f8e6d"
          }
        },
        "1d04fee0210e497fba10a4d4da0bec33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e06c9b17e7674a29944c72af5f49d638",
            "placeholder": "​",
            "style": "IPY_MODEL_673741582b4a46a092070376eba13f4a",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "323ddca7d9664e1fafb30b907c80c6e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_672e915869fe43c597e6b8e59f41cae6",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39b3e63bcfb74783bc70546b098147f2",
            "value": 4
          }
        },
        "ece885f1d1b345be9ac7e597139bc5af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_394e948f49084d4fa9c48e68dacbe14d",
            "placeholder": "​",
            "style": "IPY_MODEL_e921f73f6ae84f7e81ca0a7503ff5556",
            "value": " 4/4 [01:06&lt;00:00, 14.35s/it]"
          }
        },
        "bceffb0daa31475c84f69664726f8e6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e06c9b17e7674a29944c72af5f49d638": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "673741582b4a46a092070376eba13f4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "672e915869fe43c597e6b8e59f41cae6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39b3e63bcfb74783bc70546b098147f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "394e948f49084d4fa9c48e68dacbe14d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e921f73f6ae84f7e81ca0a7503ff5556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a36898f34584478a99ca7940343cf944": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15820a86ff00414a9469385c30acb5a8",
              "IPY_MODEL_0d4be9bd63b34d7ab90cf157f049a9a6",
              "IPY_MODEL_de1fef75dc9640f79b794442f1c88c72"
            ],
            "layout": "IPY_MODEL_115257e4a52c4d55b68b4b520a8b3075"
          }
        },
        "15820a86ff00414a9469385c30acb5a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aef36580656548e48ec3443b83eafcc3",
            "placeholder": "​",
            "style": "IPY_MODEL_0014ab3b51544f63aec85b941b9c06ff",
            "value": "generation_config.json: 100%"
          }
        },
        "0d4be9bd63b34d7ab90cf157f049a9a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3489ead55cad473cbb71a25e096a8c4d",
            "max": 182,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a3a67b4e1f8443258328b5bf7b558677",
            "value": 182
          }
        },
        "de1fef75dc9640f79b794442f1c88c72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67ce232d10994972b7bd4f1e0dddacc0",
            "placeholder": "​",
            "style": "IPY_MODEL_3bbfd9448695477894bd65e5ceaeeeea",
            "value": " 182/182 [00:00&lt;00:00, 11.9kB/s]"
          }
        },
        "115257e4a52c4d55b68b4b520a8b3075": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aef36580656548e48ec3443b83eafcc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0014ab3b51544f63aec85b941b9c06ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3489ead55cad473cbb71a25e096a8c4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3a67b4e1f8443258328b5bf7b558677": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67ce232d10994972b7bd4f1e0dddacc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bbfd9448695477894bd65e5ceaeeeea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "817a988fe4f6491dbf79402e3a5628a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1e38b6e1bc14a85ad047a3438b84bf1",
              "IPY_MODEL_ae4d762dda04487aa82ed0cc0690bee9",
              "IPY_MODEL_693ebde6a3a4489e8b738fc88724c58b"
            ],
            "layout": "IPY_MODEL_74e71d6245c542d6b08a51e536579024"
          }
        },
        "a1e38b6e1bc14a85ad047a3438b84bf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_974b2a1072cb4fbea41a02009700d2d0",
            "placeholder": "​",
            "style": "IPY_MODEL_4a0913aab07b444ba21d135bb815b4bf",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "ae4d762dda04487aa82ed0cc0690bee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95d41e52868e45e392680d3a8cd35ab8",
            "max": 50977,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52eeb3c9036442e8950362fd0a3411ee",
            "value": 50977
          }
        },
        "693ebde6a3a4489e8b738fc88724c58b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4296561136a42b793868e3f1e0f1f03",
            "placeholder": "​",
            "style": "IPY_MODEL_f2017185f35e4b01bd38481d6cc0418b",
            "value": " 51.0k/51.0k [00:00&lt;00:00, 799kB/s]"
          }
        },
        "74e71d6245c542d6b08a51e536579024": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "974b2a1072cb4fbea41a02009700d2d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a0913aab07b444ba21d135bb815b4bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95d41e52868e45e392680d3a8cd35ab8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52eeb3c9036442e8950362fd0a3411ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b4296561136a42b793868e3f1e0f1f03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2017185f35e4b01bd38481d6cc0418b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6371103d5f514240b3f3a5624e4b87ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_922833baa7f240cf9d71acfdd7b0d746",
              "IPY_MODEL_8cdc7982013b4ae494f884783b8f741e",
              "IPY_MODEL_d55de7d4a0ca444a931b5dc34886f574"
            ],
            "layout": "IPY_MODEL_18047eccf09945b485f52fbf673befe5"
          }
        },
        "922833baa7f240cf9d71acfdd7b0d746": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_169aa6ac43364d4a830e7cff66068f01",
            "placeholder": "​",
            "style": "IPY_MODEL_6be08375e05c461a8e47c417f723295a",
            "value": "tokenizer.json: 100%"
          }
        },
        "8cdc7982013b4ae494f884783b8f741e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_130e0f4edbe24bc4b567b2ad2e933c51",
            "max": 9084490,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a09f8d900e934d2c89cd23265c17165b",
            "value": 9084490
          }
        },
        "d55de7d4a0ca444a931b5dc34886f574": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26daabe978514dd8bac9710e90c71db2",
            "placeholder": "​",
            "style": "IPY_MODEL_2caf13bf0c4a482e91ac0c8b89a18e40",
            "value": " 9.08M/9.08M [00:00&lt;00:00, 17.4MB/s]"
          }
        },
        "18047eccf09945b485f52fbf673befe5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "169aa6ac43364d4a830e7cff66068f01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6be08375e05c461a8e47c417f723295a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "130e0f4edbe24bc4b567b2ad2e933c51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a09f8d900e934d2c89cd23265c17165b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "26daabe978514dd8bac9710e90c71db2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2caf13bf0c4a482e91ac0c8b89a18e40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31f4e239e7e4419abeb45c0eaca91615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92a45b06f6464aefb7d1d3d0e21a65cd",
              "IPY_MODEL_5f872c8f669a44ca9e2e3cf1484b5bea",
              "IPY_MODEL_305729df068e46a09247a959f5dd797d"
            ],
            "layout": "IPY_MODEL_efb79297853b4b94b4b906d9a0e89576"
          }
        },
        "92a45b06f6464aefb7d1d3d0e21a65cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bec6387569448f18bdcbcfab75ea235",
            "placeholder": "​",
            "style": "IPY_MODEL_f8cd2e92fde94f9d8edf727d67cf8a08",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "5f872c8f669a44ca9e2e3cf1484b5bea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cea35771f4e44add9be2171c762e8a62",
            "max": 296,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c0102a20c8aa4dbbb61d59d6a0c6dfe4",
            "value": 296
          }
        },
        "305729df068e46a09247a959f5dd797d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b164c810b8df4fd3aac876383e553a06",
            "placeholder": "​",
            "style": "IPY_MODEL_4619dc17dd5a4b168dcd4bec7b4c0651",
            "value": " 296/296 [00:00&lt;00:00, 24.0kB/s]"
          }
        },
        "efb79297853b4b94b4b906d9a0e89576": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bec6387569448f18bdcbcfab75ea235": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8cd2e92fde94f9d8edf727d67cf8a08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cea35771f4e44add9be2171c762e8a62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0102a20c8aa4dbbb61d59d6a0c6dfe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b164c810b8df4fd3aac876383e553a06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4619dc17dd5a4b168dcd4bec7b4c0651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}